#!/usr/bin/env python3
"""
Data Processor with Multiprocessing
ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•œ ê³ ì† ë°ì´í„° ì²˜ë¦¬ ëª¨ë“ˆ
"""

import struct
import time
import logging
import requests
import multiprocessing as mp
from multiprocessing import Process, Queue, Manager
from typing import Dict, Any, Optional, List
import numpy as np
import os
import sys

def _worker_process_protobuf(input_queue: mp.Queue, output_queue: mp.Queue, config: Dict[str, Any],
                             worker_id: int, timing_dict: Optional[Dict] = None):
    """
    ğŸš€ v2.1.0: ë©€í‹°í”„ë¡œì„¸ì‹± ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ (íƒ€ì´ë° ì¸¡ì • ì¶”ê°€)

    Args:
        input_queue: ì…ë ¥ ë©”ì‹œì§€ í
        output_queue: ì¶œë ¥ ê²°ê³¼ í
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        worker_id: ì›Œì»¤ ID
        timing_dict: íƒ€ì´ë° ì •ë³´ë¥¼ ê³µìœ í•  Manager.dict()
    """
    # ê° ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ DataProcessorë¥¼ import
    # (ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ ê° í”„ë¡œì„¸ìŠ¤ëŠ” ë…ë¦½ëœ Python ì¸í„°í”„ë¦¬í„°)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)

    # sys.path ì„¤ì •
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    if parent_dir not in sys.path:
        sys.path.insert(0, parent_dir)

    # DataProcessor import
    try:
        from src.data_processor import DataProcessor
    except ImportError:
        # fallback: ì§ì ‘ íŒŒì¼ì—ì„œ import
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "data_processor",
            os.path.join(current_dir, "data_processor.py")
        )
        data_processor_module = importlib.util.module_from_spec(spec)
        sys.modules['data_processor'] = data_processor_module
        spec.loader.exec_module(data_processor_module)
        DataProcessor = data_processor_module.DataProcessor

    # ê° ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ì—ì„œ ë…ë¦½ì ì¸ DataProcessor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    processor = DataProcessor(config)

    # ë¡œê¹… ì„¤ì • (ì›Œì»¤ë³„ë¡œ êµ¬ë¶„)
    logger = logging.getLogger(f"worker_{worker_id}")

    logger.info(f"ğŸ”§ ì›Œì»¤ {worker_id} ì‹œì‘")

    # ë¡œì»¬ íƒ€ì´ë° í†µê³„
    local_timing = {
        'protobuf_parse_ms': [],
        'ros_msg_build_ms': [],
        'total_process_ms': []
    }

    while True:
        try:
            # ì…ë ¥ íì—ì„œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 1ì´ˆ)
            message_data = input_queue.get(timeout=1.0)

            # ì¢…ë£Œ ì‹ í˜¸ í™•ì¸
            if message_data is None:
                logger.info(f"ğŸ›‘ ì›Œì»¤ {worker_id} ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
                break

            # ğŸš€ v2.1.0: ë‹¨ê³„ë³„ íƒ€ì´ë° ì¸¡ì •
            timing_start = time.time()

            # Protobuf íŒŒì‹± ì‹œê°„ ì¸¡ì • (DataProcessor ë‚´ë¶€ì—ì„œ ì¸¡ì •ë¨)
            result = processor.process_message(message_data)

            total_time_ms = (time.time() - timing_start) * 1000

            # ë¡œì»¬ íƒ€ì´ë° ì €ì¥
            local_timing['total_process_ms'].append(total_time_ms)

            # ì£¼ê¸°ì ìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸ (100íšŒë§ˆë‹¤)
            if len(local_timing['total_process_ms']) >= 100 and timing_dict is not None:
                avg_total = sum(local_timing['total_process_ms']) / len(local_timing['total_process_ms'])
                timing_dict[f'worker_{worker_id}_avg_ms'] = avg_total
                local_timing['total_process_ms'] = []  # ë¦¬ì…‹

            # ê²°ê³¼ë¥¼ ì¶œë ¥ íì— ë„£ê¸°
            if result:
                output_queue.put({
                    'worker_id': worker_id,
                    'result': result,
                    'process_time': total_time_ms / 1000  # ì´ˆ ë‹¨ìœ„
                })

        except mp.queues.Empty:
            # íƒ€ì„ì•„ì›ƒ ë°œìƒ - ì •ìƒì ì¸ ìƒí™©, ê³„ì† ëŒ€ê¸°
            continue
        except KeyboardInterrupt:
            # ğŸš€ Graceful shutdown: Ctrl+C ì‹œ ê¹¨ë—í•˜ê²Œ ì¢…ë£Œ
            logger.info(f"âŒ¨ï¸  ì›Œì»¤ {worker_id}: ì‚¬ìš©ì ì¤‘ë‹¨ ì‹ í˜¸ ìˆ˜ì‹ , ì •ë¦¬ ì¤‘...")
            break
        except Exception as e:
            # ì‹¤ì œ ì—ëŸ¬ ë°œìƒ - ìƒì„¸ ì •ë³´ ì¶œë ¥
            import traceback
            logger.error(f"ì›Œì»¤ {worker_id} ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
            logger.error(f"ìƒì„¸:\n{traceback.format_exc()}")
            continue

    logger.info(f"âœ… ì›Œì»¤ {worker_id} ì¢…ë£Œ")


class DataProcessorMultiprocessing:
    """ğŸš€ v2.1.0: ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•˜ëŠ” ê³ ì† ë°ì´í„° í”„ë¡œì„¸ì„œ (ì ì‘í˜• ì›Œì»¤ í’€)"""

    def __init__(self, config: Dict[str, Any], num_workers: int = 4):
        """
        DataProcessorMultiprocessing ì´ˆê¸°í™”

        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            num_workers: ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìˆ˜ (ê¸°ë³¸ê°’: 4)
        """
        self.config = config
        self.logger = logging.getLogger(__name__)

        # ğŸš€ v2.1.0: ì„¤ì •ì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± íŒŒë¼ë¯¸í„° ì½ê¸°
        mp_config = config.get('multiprocessing', {})
        self.num_workers = mp_config.get('num_workers', num_workers)
        self.max_workers = mp_config.get('max_workers', num_workers * 2)
        self.scale_up_threshold = mp_config.get('scale_up_threshold', 50)
        self.scale_down_seconds = mp_config.get('scale_down_seconds', 30)

        # í í¬ê¸°
        input_queue_size = mp_config.get('input_queue_size', 100)
        output_queue_size = mp_config.get('output_queue_size', 1000)

        self.input_queue = mp.Queue(maxsize=input_queue_size)
        self.output_queue = mp.Queue(maxsize=output_queue_size)

        # ğŸš€ v2.1.0: íƒ€ì´ë° ì •ë³´ ê³µìœ ë¥¼ ìœ„í•œ Manager
        self.manager = Manager()
        self.timing_dict = self.manager.dict()

        # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ë¦¬ìŠ¤íŠ¸
        self.workers = []

        # ì ì‘í˜• ì›Œì»¤ í’€ ìƒíƒœ
        self.last_scale_check_time = time.time()
        self.last_busy_time = time.time()

        # í†µê³„
        self.stats = {
            'total_processed': 0,
            'total_dropped': 0,
            'process_times': [],
        }

        self.is_running = False

    def start(self):
        """ğŸš€ v2.1.0: ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (íƒ€ì´ë° ì¸¡ì • í¬í•¨)"""
        if self.is_running:
            self.logger.warning("ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return

        self.is_running = True

        # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        for i in range(self.num_workers):
            worker = Process(
                target=_worker_process_protobuf,
                args=(self.input_queue, self.output_queue, self.config, i, self.timing_dict),
                daemon=True
            )
            worker.start()
            self.workers.append(worker)

        self.logger.info(f"ğŸš€ ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘: {self.num_workers}ê°œ ì›Œì»¤ (ìµœëŒ€: {self.max_workers}ê°œ)")

    def stop(self):
        """ğŸš€ v2.1.0: ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì •ìƒ ì¢…ë£Œ"""
        if not self.is_running:
            return

        self.is_running = False

        # ëª¨ë“  ì›Œì»¤ì— ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
        for _ in range(len(self.workers)):
            try:
                self.input_queue.put(None, timeout=1)
            except:
                pass

        # ëª¨ë“  ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ëŒ€ê¸°
        shutdown_timeout = self.config.get('shutdown', {}).get('timeout_s', 10)
        for worker in self.workers:
            worker.join(timeout=shutdown_timeout)
            if worker.is_alive():
                self.logger.warning(f"ì›Œì»¤ê°€ ì •ìƒ ì¢…ë£Œë˜ì§€ ì•Šì•„ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤: PID {worker.pid}")
                worker.terminate()

        self.workers.clear()
        self.logger.info("ğŸ›‘ ë©€í‹°í”„ë¡œì„¸ì‹± ì¤‘ì§€")

        # Manager ì •ë¦¬
        try:
            self.manager.shutdown()
        except:
            pass

    def process_message(self, message_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ë©”ì‹œì§€ë¥¼ ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ì— ì „ë‹¬ (ë¹„ë¸”ë¡œí‚¹)

        Args:
            message_data: SENSR ë©”ì‹œì§€ ë°ì´í„°

        Returns:
            None (ê²°ê³¼ëŠ” get_result()ë¡œ ê°€ì ¸ì˜´)
        """
        if not self.is_running:
            self.logger.warning("ë©€í‹°í”„ë¡œì„¸ì‹±ì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        try:
            # ì…ë ¥ íì— ë©”ì‹œì§€ ì¶”ê°€ (ë¹„ë¸”ë¡œí‚¹)
            self.input_queue.put_nowait(message_data)
            return None  # ë¹„ë™ê¸° ì²˜ë¦¬

        except Exception as e:
            self.stats['total_dropped'] += 1
            self.logger.warning(f"ì…ë ¥ í ê°€ë“ì°¸! ë©”ì‹œì§€ ë“œë¡­ (ì´ {self.stats['total_dropped']}ê°œ)")
            return None

    def get_result(self, timeout: float = 0.1) -> Optional[Dict[str, Any]]:
        """
        ì²˜ë¦¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°

        Args:
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

        Returns:
            ì²˜ë¦¬ëœ ê²°ê³¼ ë˜ëŠ” None
        """
        try:
            result_data = self.output_queue.get(timeout=timeout)

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['total_processed'] += 1
            self.stats['process_times'].append(result_data['process_time'])

            return result_data['result']

        except:
            return None

    def get_results_batch(self, max_count: int = 50, timeout: float = 0.01) -> List[Dict[str, Any]]:
        """
        ğŸš€ Phase 2: ì—¬ëŸ¬ ê²°ê³¼ë¥¼ ë°°ì¹˜ë¡œ ê°€ì ¸ì˜¤ê¸° (2-5ë°° ì„±ëŠ¥ í–¥ìƒ)

        Args:
            max_count: ìµœëŒ€ ê°€ì ¸ì˜¬ ê²°ê³¼ ê°œìˆ˜
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

        Returns:
            ì²˜ë¦¬ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        deadline = time.time() + timeout

        while len(results) < max_count and time.time() < deadline:
            try:
                result_data = self.output_queue.get_nowait()

                # í†µê³„ ì—…ë°ì´íŠ¸
                self.stats['total_processed'] += 1
                self.stats['process_times'].append(result_data['process_time'])

                results.append(result_data['result'])

            except:
                # íê°€ ë¹„ì—ˆê±°ë‚˜ íƒ€ì„ì•„ì›ƒ
                if len(results) > 0:
                    # ì´ë¯¸ ì¼ë¶€ ê²°ê³¼ë¥¼ ì–»ì—ˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
                    break
                # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì§§ê²Œ ëŒ€ê¸°
                time.sleep(0.001)  # 1ms

        return results

    def _scale_workers(self):
        """
        ğŸš€ v2.1.0: ì ì‘í˜• ì›Œì»¤ í’€ - ë¶€í•˜ì— ë”°ë¼ ì›Œì»¤ ìˆ˜ ì¡°ì ˆ
        """
        if not self.is_running:
            return

        current_time = time.time()

        # ì£¼ê¸°ì  ì²´í¬ (5ì´ˆë§ˆë‹¤)
        if current_time - self.last_scale_check_time < 5.0:
            return

        self.last_scale_check_time = current_time

        try:
            input_qsize = self.input_queue.qsize()
            current_worker_count = len(self.workers)

            # Scale Up: ì…ë ¥ íê°€ ì„ê³„ê°’ ì´ìƒì´ê³  ì›Œì»¤ ìˆ˜ê°€ ìµœëŒ€ë³´ë‹¤ ì ìœ¼ë©´
            if input_qsize >= self.scale_up_threshold and current_worker_count < self.max_workers:
                new_worker_id = current_worker_count
                worker = Process(
                    target=_worker_process_protobuf,
                    args=(self.input_queue, self.output_queue, self.config, new_worker_id, self.timing_dict),
                    daemon=True
                )
                worker.start()
                self.workers.append(worker)
                self.logger.info(f"ğŸš€ ì›Œì»¤ ì¶”ê°€: {current_worker_count} â†’ {len(self.workers)}ê°œ (í í¬ê¸°: {input_qsize})")
                self.last_busy_time = current_time

            # Scale Down: ì¼ì • ì‹œê°„ idleì´ê³  ì›Œì»¤ ìˆ˜ê°€ ì´ˆê¸°ê°’ë³´ë‹¤ ë§ìœ¼ë©´
            elif input_qsize < self.scale_up_threshold // 2 and current_worker_count > self.num_workers:
                idle_time = current_time - self.last_busy_time
                if idle_time >= self.scale_down_seconds:
                    # ë§ˆì§€ë§‰ ì›Œì»¤ ì œê±°
                    worker = self.workers.pop()
                    try:
                        self.input_queue.put(None, timeout=0.5)
                        worker.join(timeout=2)
                        if worker.is_alive():
                            worker.terminate()
                        self.logger.info(f"ğŸ”½ ì›Œì»¤ ì œê±°: {current_worker_count} â†’ {len(self.workers)}ê°œ (idle: {idle_time:.1f}ì´ˆ)")
                    except:
                        self.workers.append(worker)  # ì œê±° ì‹¤íŒ¨ ì‹œ ë³µì›

            # íì— ì‘ì—…ì´ ìˆìœ¼ë©´ busy íƒ€ì„ ì—…ë°ì´íŠ¸
            if input_qsize > 0:
                self.last_busy_time = current_time

        except Exception as e:
            self.logger.error(f"ì›Œì»¤ ìŠ¤ì¼€ì¼ë§ ì˜¤ë¥˜: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """ğŸš€ v2.1.0: í†µê³„ ì •ë³´ ë°˜í™˜ (íƒ€ì´ë° ì •ë³´ í¬í•¨)"""
        avg_process_time = 0
        if self.stats['process_times']:
            avg_process_time = sum(self.stats['process_times']) / len(self.stats['process_times'])

        # ì›Œì»¤ë³„ í‰ê·  ì²˜ë¦¬ ì‹œê°„ ìˆ˜ì§‘
        worker_timings = {}
        for key, value in self.timing_dict.items():
            worker_timings[key] = value

        return {
            'num_workers': len(self.workers),
            'max_workers': self.max_workers,
            'total_processed': self.stats['total_processed'],
            'total_dropped': self.stats['total_dropped'],
            'avg_process_time': avg_process_time,
            'input_queue_size': self.input_queue.qsize(),
            'output_queue_size': self.output_queue.qsize(),
            'worker_timings': worker_timings,
        }
