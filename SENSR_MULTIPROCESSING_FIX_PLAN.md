# SENSR ë©€í‹°í”„ë¡œì„¸ì‹± ë ˆì´ë” ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ ìˆ˜ì • ê³„íšì„œ

**ì‘ì„±ì¼**: 2025-11-12
**ë²„ì „**: 1.0
**ëŒ€ìƒ ì‹œìŠ¤í…œ**: SENSR Lidar Recorder v2 (Multiprocessing)

---

## ğŸ“‹ ìš”ì•½ (Executive Summary)

### í˜„ì¬ ë¬¸ì œì 

í…ŒìŠ¤íŠ¸ ë¡œê·¸ ë¶„ì„ ê²°ê³¼, ì‹œìŠ¤í…œì´ ë‹¤ìŒê³¼ ê°™ì€ ì‹¬ê°í•œ ì„±ëŠ¥ ë¬¸ì œë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤:

| ë¬¸ì œ | í˜„ì¬ ìƒíƒœ | ì˜í–¥ |
|------|----------|------|
| **ì²˜ë¦¬ìœ¨ ë¶ˆê· í˜•** | ìˆ˜ì‹  11.4 msg/s vs ì²˜ë¦¬ 1.4 msg/s | **8ë°° ì°¨ì´** |
| **ë©”ì‹œì§€ ì²˜ë¦¬ìœ¨** | 248ê°œ ì¤‘ 31ê°œë§Œ ì²˜ë¦¬ (21.7ì´ˆ) | **12.5%** ì²˜ë¦¬ ì„±ê³µë¥  |
| **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜** | 21.7ì´ˆ ë™ì•ˆ 238.8 MB ì¦ê°€ | **~11 MB/s** ì¦ê°€ìœ¨ |
| **ë¹„ì •ìƒ ì¢…ë£Œ** | Ctrl+C ì‹œ SystemExit ì˜ˆì™¸ ë°œìƒ | ë°ì´í„° ì†ì‹¤ ìœ„í—˜ |
| **í…ŒìŠ¤íŠ¸ ë¯¸ì™„ë£Œ** | 60ì´ˆ ëª©í‘œ ì¤‘ 21ì´ˆì—ì„œ ì¤‘ë‹¨ | **35%** ì™„ë£Œìœ¨ |

### ê°œì„  ëª©í‘œ

| í•­ëª© | í˜„ì¬ | ëª©í‘œ | ê°œì„ ìœ¨ |
|------|------|------|--------|
| ì²˜ë¦¬ìœ¨ | 1.4 msg/s | **â‰¥8 msg/s** | **5.7ë°°** |
| ë©”ì‹œì§€ ë“œë¡­ë¥  | 87.5% | **<5%** | **94.6%p ê°œì„ ** |
| ì“°ê¸° ì†ë„ | 2.3 msg/s | **â‰¥10 msg/s** | **4.3ë°°** |
| ë©”ëª¨ë¦¬ ì¦ê°€ìœ¨ | 11 MB/s | **<2 MB/s** | **5.5ë°° ê°œì„ ** |
| í…ŒìŠ¤íŠ¸ ì™„ì£¼ | 21ì´ˆ ì¤‘ë‹¨ | **60ì´ˆ ì™„ì£¼** | âœ“ |
| ì •ìƒ ì¢…ë£Œ | ì˜ˆì™¸ ë°œìƒ | **ì •ìƒ ì¢…ë£Œ** | âœ“ |

---

## ğŸ” ê·¼ë³¸ ì›ì¸ ë¶„ì„ (Root Cause Analysis)

### 1. í í¬í™” (Queue Saturation)

#### ğŸ“ ë¬¸ì œ ìœ„ì¹˜

```
íŒŒì¼: sensr_client.py
ë¼ì¸: 36
ì½”ë“œ: self.message_queue = queue.Queue(maxsize=200)

íŒŒì¼: data_processor_multiprocessing.py
ë¼ì¸: 120
ì½”ë“œ: self.input_queue = mp.Queue(maxsize=100)  âš ï¸ ì£¼ìš” ë³‘ëª©

íŒŒì¼: bag_recorder_optimized.py
ë¼ì¸: 58
ì½”ë“œ: self.message_queue = queue.Queue(maxsize=50)  âš ï¸âš ï¸ ì‹¬ê°í•œ ë³‘ëª©
```

#### ğŸ”¬ ê¸°ìˆ ì  ë¶„ì„

**íŒŒì´í”„ë¼ì¸ êµ¬ì¡°**:
```
WebSocket ìˆ˜ì‹  ì†ë„: 11.4 msg/s
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  sensr_client.message_queue     â”‚
â”‚  (200 capacity)                 â”‚  â† 17.5ì´ˆ ë²„í¼
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  processor.input_queue          â”‚
â”‚  (100 capacity)                 â”‚  â† 8.8ì´ˆ ë²„í¼ âš ï¸ í¬í™” ì§€ì 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  bag_recorder.message_queue     â”‚
â”‚  (50 capacity)                  â”‚  â† 4.4ì´ˆ ë²„í¼ âš ï¸âš ï¸
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
       ë””ìŠ¤í¬ ì“°ê¸°: 2.3 msg/s
```

**ë¬¸ì œ ë¶„ì„**:
- ì…ë ¥ ì†ë„(11.4 msg/s) > ì²˜ë¦¬ ì†ë„(1.4 msg/s) â†’ **8ë°° ë¶ˆê· í˜•**
- 100ê°œ íëŠ” 11.4 msg/s ê¸°ì¤€ **8.8ì´ˆ**ë§Œ ë²„íŒ€
- 50ê°œ íëŠ” **4.4ì´ˆ** í›„ í¬í™”
- 15:45:38 ì‹œì‘ â†’ 15:45:56 (18ì´ˆ í›„) í í¬í™” ì‹œì‘

#### ğŸ“Š ë¡œê·¸ ì¦ê±°

```log
2025-11-12 15:45:56 - src.sensr_client - WARNING - ë©”ì‹œì§€ íê°€ ê°€ë“ì°¸. ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
(ì´í›„ 46íšŒ ë°˜ë³µ)
```

**ë“œë¡­ ë¡œì§** (sensr_client.py:256-265):
```python
except queue.Full:
    self.logger.warning("ë©”ì‹œì§€ íê°€ ê°€ë“ì°¸. ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ì œê±°í•©ë‹ˆë‹¤.")
    try:
        old_message = self.message_queue.get_nowait()
        del old_message
        self.message_queue.put_nowait(message_data)
```

**ê²°ê³¼**: 248ê°œ ìˆ˜ì‹  ì¤‘ 31ê°œë§Œ ì²˜ë¦¬ â†’ **87.5% ë“œë¡­ë¥ **

---

### 2. ì²˜ë¦¬ ë³‘ëª© (Processing Bottleneck)

#### ğŸ“ ë¬¸ì œ ìœ„ì¹˜

**íŒŒì¼**: `data_processor.py`

**Lines 377-454**: Protobuf ë””ì½”ë”©
```python
def _decode_pointcloud_protobuf(self, raw_data: bytes):
    # Line 390: Protobuf íŒŒì‹± (1-8ms)
    point_result.ParseFromString(raw_data)

    # Lines 396-430: NumPy ë°°ì—´ ë³€í™˜ (5-15ms + 10-30ms)
    for i, point_cloud in enumerate(point_result.points):
        points_array = np.frombuffer(points_data, np.float32).reshape(-1, 3)
        all_points_array = np.vstack(all_points_list)  # âš ï¸ ë¹„íš¨ìœ¨ì 

    # ì´ ì²˜ë¦¬ ì‹œê°„: 4.7ms (ìµœì„ ) ~ 66.1ms (ìµœì•…), í‰ê·  ~25ms
```

**Lines 617-695**: ROS2 ë©”ì‹œì§€ ìƒì„±
```python
def _create_pointcloud2_message(self, pointcloud_data, timestamp):
    # Lines 653-692: NumPy ë°°ì—´ ì¡°ì‘ (50-200ms)
    cloud_array = np.hstack([points, intensities.reshape(-1, 1)])  # âš ï¸ ë©”ëª¨ë¦¬ ë³µì‚¬

    # Line 692: ì§ë ¬í™” (20-50ms)
    msg.data = cloud_array.tobytes()  # âš ï¸ ì „ì²´ ë³µì‚¬

    # ì´ ì²˜ë¦¬ ì‹œê°„: ~150ms
```

#### ğŸ”¬ ì„±ëŠ¥ í”„ë¡œíŒŒì¼

**ë‹¨ì¼ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œê°„** (ë¡œê·¸ í‰ê·  329ms):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Protobuf íŒŒì‹±          : ~25ms  ( 7.6%)   â”‚
â”‚ NumPy ë°°ì—´ ë³€í™˜         : ~100ms (30.4%)   â”‚
â”‚ PointCloud2 ë©”ì‹œì§€ ìƒì„± : ~150ms (45.6%)   â”‚
â”‚ í ëŒ€ê¸° / GIL ê²½í•©      : ~54ms  (16.4%)   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ ì´í•©                    : 329ms  (100%)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì´ë¡ ì  ì²˜ë¦¬ëŸ‰:
  4 ì›Œì»¤ Ã— (1 / 0.329ì´ˆ) = 12.1 msg/s

ì‹¤ì œ ë‹¬ì„±:
  1.4 msg/s (ì´ë¡ ê°’ì˜ 11.6%)

íš¨ìœ¨ì„± ì†ì‹¤ ì›ì¸:
  - GIL (Global Interpreter Lock) ê²½í•©
  - ë©”ëª¨ë¦¬ ë³µì‚¬ ì˜¤ë²„í—¤ë“œ (vstack, hstack, tobytes)
  - í ëŒ€ê¸° ì‹œê°„
  - í”„ë¡œì„¸ìŠ¤ê°„ í†µì‹  ì˜¤ë²„í—¤ë“œ
```

#### ğŸ“Š ë¡œê·¸ ì¦ê±°

```log
2025-11-12 15:45:39 - íŒŒì‹± ì™„ë£Œ: 921512ê°œ í¬ì¸íŠ¸ (ì´ 66.1ms)
2025-11-12 15:45:41 - íŒŒì‹± ì™„ë£Œ: 921516ê°œ í¬ì¸íŠ¸ (ì´ 15.9ms)
2025-11-12 15:45:43 - íŒŒì‹± ì™„ë£Œ: 921506ê°œ í¬ì¸íŠ¸ (ì´ 28.0ms)

ìµœì¢… í†µê³„:
  í‰ê·  ì²˜ë¦¬ ì‹œê°„: 329.11ms
  ì›Œì»¤ ìˆ˜: 4ê°œ
  ì´ ì²˜ë¦¬: 31ê°œ (21.7ì´ˆ ë™ì•ˆ)
  ì²˜ë¦¬ìœ¨: 31 / 21.7 = 1.4 msg/s
```

**ì›Œì»¤ íš¨ìœ¨ì„±**:
- ì›Œì»¤ë‹¹ ì²˜ë¦¬ëŸ‰: 1.4 / 4 = **0.35 msg/s**
- ì´ë¡ ê°’: 1 / 0.329 = 3.04 msg/s
- íš¨ìœ¨ì„±: 0.35 / 3.04 = **11.5%** âš ï¸

---

### 3. ë””ìŠ¤í¬ ì“°ê¸° ë³‘ëª© (Disk Write Bottleneck)

#### ğŸ“ ë¬¸ì œ ìœ„ì¹˜

**íŒŒì¼**: `bag_recorder_optimized.py`

**Lines 255-335**: ë‹¨ì¼ ë©”ì‹œì§€ ë™ê¸° ì“°ê¸°
```python
def _recording_worker(self):
    while self.is_recording:
        message_data = self.message_queue.get(timeout=1.0)

        # í† í”½ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (~2ms)
        message_type = message_data['message'].__class__

        # í† í”½ ìƒì„± (ì²« ë©”ì‹œì§€ë§Œ, ~50ms)
        if topic_name not in self.created_topics:
            self.current_writer.create_topic(topic_metadata)

        # ROS2 ì§ë ¬í™” + SQLite3 ì“°ê¸° (ë™ê¸°, ~350ms)
        serialized_msg = serialize_message(message_data['message'])  # ~150ms
        self.current_writer.write(topic_name, serialized_msg, ...)  # ~200ms

        # ì´: ~400ms per message
```

**Lines 338-393**: ë°°ì¹˜ ì“°ê¸° ì½”ë“œ ì¡´ì¬í•˜ì§€ë§Œ **ì‚¬ìš© ì•ˆ ë¨** âš ï¸
```python
def _flush_batch(self):
    """ë°°ì¹˜ ë²„í¼ë¥¼ í”ŒëŸ¬ì‹œ (ì •ì˜ë˜ì–´ ìˆìœ¼ë‚˜ í˜¸ì¶œ ì•ˆ ë¨)"""
    # ì´ í•¨ìˆ˜ëŠ” shutdown ì‹œì—ë§Œ ì‚¬ìš©ë¨ (lines 241-242)
    # ë©”ì¸ ì“°ê¸° ê²½ë¡œì—ì„œëŠ” ì‚¬ìš© ì•ˆ í•¨!
```

#### ğŸ”¬ ê¸°ìˆ ì  ë¶„ì„

**ROS2 Bag Write íŒŒì´í”„ë¼ì¸**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ serialize_message()   : ~150ms          â”‚  (CDR ì§ë ¬í™”)
â”‚ SQLite3 INSERT        : ~200ms          â”‚  (ë””ìŠ¤í¬ I/O, fsync)
â”‚ Index ì—…ë°ì´íŠ¸         : ~50ms           â”‚  (ë©”íƒ€ë°ì´í„°)
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ ì´í•©                  : ~400ms          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì´ë¡ ì  ì“°ê¸° ì†ë„: 1 / 0.4ì´ˆ = 2.5 msg/s
ì‹¤ì œ ë‹¬ì„±: 2.3 msg/s (ì´ë¡ ê°’ì˜ 92%)
```

**SQLite3 íŠ¹ì„±**:
- Backend: SQLite3 (ROS2 rosbag2 ê¸°ë³¸ê°’)
- Journal ëª¨ë“œ: ê¸°ë³¸ê°’ (DELETE ë˜ëŠ” WAL)
- Synchronous: FULL (ëª¨ë“  ì“°ê¸° í›„ fsync)
- ê²°ê³¼: **ë™ê¸° I/Oë¡œ ì¸í•œ ë³‘ëª©**

#### ğŸ“Š ë¡œê·¸ ì¦ê±°

```log
ìµœì¢… í†µê³„:
  ì´ ì“°ê¸°: 51ê°œ
  ì‹¤í–‰ ì‹œê°„: 21.7ì´ˆ
  ì“°ê¸° ì†ë„: 51 / 21.7 = 2.3 msg/s
```

**ë¬¸ì œ**:
- ì“°ê¸° ì†ë„(2.3 msg/s) > ì²˜ë¦¬ ì†ë„(1.4 msg/s) â†’ í˜„ì¬ëŠ” ë¬¸ì œ ì—†ìŒ
- **í•˜ì§€ë§Œ** ì²˜ë¦¬ ì†ë„ê°€ 8 msg/së¡œ ì¦ê°€í•˜ë©´ â†’ **ì“°ê¸°ê°€ ë³‘ëª©**
- ë°°ì¹˜ ì“°ê¸° ë¯¸ì‚¬ìš©ìœ¼ë¡œ I/O íšŸìˆ˜ ê³¼ë‹¤

---

### 4. SystemExit ì˜ˆì™¸ (Shutdown Exception)

#### ğŸ“ ë¬¸ì œ ìœ„ì¹˜

**íŒŒì¼**: `utils.py`

**Lines 217-234**: ì‹œê·¸ë„ í•¸ë“¤ëŸ¬
```python
def create_signal_handler(cleanup_func):
    def signal_handler(sig, frame):
        print(f"\nì‹œê·¸ë„ {sig} ìˆ˜ì‹ . í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤...")
        if cleanup_func:
            cleanup_func()
        sys.exit(0)  # âš ï¸ LINE 231: SystemExit ì˜ˆì™¸ ë°œìƒ!

    return signal_handler
```

#### ğŸ”¬ ì‹¤í–‰ íë¦„ ë¶„ì„

**Ctrl+C ëˆŒë €ì„ ë•Œ ë°œìƒ ìˆœì„œ**:

```
1. ì‚¬ìš©ì: Ctrl+C
        â†“
2. OS: SIGINT ì‹ í˜¸ ë°œìƒ
        â†“
3. Python: signal_handler() í˜¸ì¶œ
        â†“
4. cleanup_func() ì‹¤í–‰ (self.stop())
   - WebSocket ì—°ê²° ì¢…ë£Œ ì‹œë„
   - ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
   - Bag íŒŒì¼ ë‹«ê¸° ì‹œë„
        â†“
5. sys.exit(0) í˜¸ì¶œ â†’ SystemExit ì˜ˆì™¸ ë°œìƒ âš ï¸
        â†“
6. multiprocessing.Process.join() ì‹¤í–‰ ì¤‘
   - ë¶€ëª¨ í”„ë¡œì„¸ìŠ¤ê°€ ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸° ì¤‘
   - ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ë“¤ì´ finalizer ì‹¤í–‰ ì¤‘
        â†“
7. SystemExitë¡œ ì¸í•´ ë¶€ëª¨ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨
        â†“
8. ì›Œì»¤ finalizerê°€ interrupted
        â†“
9. Exception in atexit callback:
   SystemExit: 0
```

#### ğŸ“Š ë¡œê·¸ ì¦ê±°

```log
^C2025-11-12 15:45:59 - worker_1 - INFO - âŒ¨ï¸ ì›Œì»¤ 1: ì‚¬ìš©ì ì¤‘ë‹¨ ì‹ í˜¸ ìˆ˜ì‹ , ì •ë¦¬ ì¤‘...
2025-11-12 15:45:59 - worker_3 - INFO - âŒ¨ï¸ ì›Œì»¤ 3: ì‚¬ìš©ì ì¤‘ë‹¨ ì‹ í˜¸ ìˆ˜ì‹ , ì •ë¦¬ ì¤‘...
ì‹œê·¸ë„ 2 ìˆ˜ì‹ . í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤...
...
Exception ignored in atexit callback: <function _exit_function at 0x77ab43d36830>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 360, in _exit_function
    _run_finalizers()
  ...
  File ".../src/utils.py", line 231, in signal_handler
    sys.exit(0)
SystemExit: 0
```

**ë¬¸ì œì **:
- `sys.exit(0)`ëŠ” SystemExit ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚´
- ë©€í‹°í”„ë¡œì„¸ì‹± ì •ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ â†’ ë¹„ì •ìƒ ì¢…ë£Œ
- ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ê°€ ì •ë¦¬ ì™„ë£Œ ì „ì— ì¢…ë£Œ â†’ ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥
- ìµœì¢… ë¦¬í¬íŠ¸ê°€ ì¶œë ¥ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ

---

### 5. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ (Memory Leak)

#### ğŸ“ ë¬¸ì œ ìœ„ì¹˜

**íŒŒì¼**: `data_processor.py`

**Lines 140-142**: ê°ì²´ í’€ (ë„ˆë¬´ ì‘ìŒ)
```python
# Phase 3: Message object reuse pool (GC reduction)
self.header_pool = []
self.max_pool_size = 20  # âš ï¸ 20ê°œë§Œ (ë¶€ì¡±)
```

**Lines 867-897**: í—¤ë” ìƒì„± (ìƒˆ ê°ì²´ ë¹ˆë²ˆ ìƒì„±)
```python
def _create_ros_header(self, timestamp):
    if self.header_pool:
        header = self.header_pool.pop()
    else:
        header = Header()  # âš ï¸ í’€ì´ ë¹„ë©´ ìƒˆ ê°ì²´ ìƒì„±
    # ...
```

**Lines 899-907**: ì¬í™œìš© í•¨ìˆ˜ (í˜¸ì¶œ ì•ˆ ë¨!)
```python
def recycle_header(self, header):
    """í—¤ë” ì¬í™œìš© (ì´ í•¨ìˆ˜ê°€ ì–´ë””ì„œë„ í˜¸ì¶œë˜ì§€ ì•ŠìŒ!)"""
    if len(self.header_pool) < self.max_pool_size:
        self.header_pool.append(header)
```

#### ğŸ”¬ ë©”ëª¨ë¦¬ ì¦ê°€ ë¶„ì„

**ë©”ëª¨ë¦¬ í†µê³„**:
```
ì‹œì‘ ë©”ëª¨ë¦¬:   227.0 MB
ì¢…ë£Œ ë©”ëª¨ë¦¬:   465.8 MB
ì¦ê°€ëŸ‰:       238.8 MB
ì‹¤í–‰ ì‹œê°„:     21.7ì´ˆ
ì¦ê°€ìœ¨:       238.8 / 21.7 = 11.0 MB/s

ì²˜ë¦¬ ë©”ì‹œì§€:   31ê°œ
ë©”ì‹œì§€ë‹¹:     238.8 / 31 = 7.7 MB per message
```

**PointCloud2 ë©”ì‹œì§€ í¬ê¸° ë¶„ì„**:
```
í¬ì¸íŠ¸ ìˆ˜: 921,512ê°œ (í‰ê· )
ë°ì´í„° í¬ê¸°:
  - í¬ì¸íŠ¸ (x,y,z): 921,512 Ã— 12 bytes = 10.5 MB
  - ê°•ë„ (intensity): 921,512 Ã— 4 bytes = 3.5 MB
  - ë©”íƒ€ë°ì´í„°: ~0.3 MB
  - ì´: ~14.3 MB per message (ì••ì¶• ì „)

ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê³„ì‚°:
  - Protobuf ê°ì²´: ~15 MB Ã— 31 = 465 MB (ëˆ„ì )
  - NumPy ì¤‘ê°„ ë°°ì—´: ì¶”ê°€ ë©”ëª¨ë¦¬
  - ROS2 ë©”ì‹œì§€: ì§ë ¬í™” í›„ ë¯¸ì‚­ì œ
  - í ë‚´ë¶€ ì°¸ì¡°: 100+50 = 150ê°œ ë©”ì‹œì§€ ìƒì£¼
```

**ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì†ŒìŠ¤**:

1. **Protobuf ê°ì²´** (data_processor.py:377-454)
   - `point_result` ê°ì²´ê°€ í•¨ìˆ˜ ë°˜í™˜ í›„ì—ë„ ì°¸ì¡° ìœ ì§€
   - `del point_result` í˜¸ì¶œ ì•ˆ ë¨

2. **NumPy ë°°ì—´** (data_processor.py:396-430)
   - `all_points_list`ì˜ ì¤‘ê°„ ë°°ì—´ë“¤ì´ ë©”ëª¨ë¦¬ì— ë‚¨ìŒ
   - `np.vstack()` í˜¸ì¶œë§ˆë‹¤ ìƒˆ ë°°ì—´ ìƒì„±

3. **ROS2 ë©”ì‹œì§€** (main_multiprocessing.py:166-192)
   - ì²˜ë¦¬ ê²°ê³¼ `msg_info` ê°ì²´ ì‚­ì œ ì•ˆ ë¨
   - íì— ìŒ“ì¸ ë©”ì‹œì§€ë“¤ì´ ì°¸ì¡° ìœ ì§€

4. **ê°ì²´ í’€ ë¯¸ì‚¬ìš©**
   - `recycle_header()` í•¨ìˆ˜ í˜¸ì¶œ ì•ˆ ë¨
   - í’€ í¬ê¸° 20ê°œë¡œ ë¶€ì¡± (ë©”ì‹œì§€ë‹¹ ì—¬ëŸ¬ í—¤ë” ê°ì²´ í•„ìš”)

#### ğŸ“Š ë¡œê·¸ ì¦ê±°

```log
ğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤:
  - ë©”ëª¨ë¦¬ (í‰ê· ): 336.7 MB
  - ë©”ëª¨ë¦¬ (ìµœì†Œ): 227.0 MB
  - ë©”ëª¨ë¦¬ (ìµœëŒ€): 465.8 MB
  - ë©”ëª¨ë¦¬ ì¦ê°€: 238.8 MB
```

**ì˜ˆì¸¡**:
- 60ì´ˆ í…ŒìŠ¤íŠ¸ ì‹œ: 11 MB/s Ã— 60 = **660 MB ì¦ê°€**
- 10ë¶„ ì‹¤í–‰ ì‹œ: 11 MB/s Ã— 600 = **6.6 GB ì¦ê°€** â†’ OOM ìœ„í—˜

---

## ğŸ¯ ìˆ˜ì • ê³„íš (Fix Plan)

### Priority 1: í ê´€ë¦¬ ë° ë°±í”„ë ˆì…” ì‹œìŠ¤í…œ

#### ëª©í‘œ
- âœ… ë©”ì‹œì§€ ë“œë¡­ ì—†ì´ 60ì´ˆ í…ŒìŠ¤íŠ¸ ì™„ì£¼
- âœ… í í¬í™” ê²½ê³  ì œê±°
- âœ… ë™ì  ë°±í”„ë ˆì…”ë¡œ WebSocket ìˆ˜ì‹  ì†ë„ ì¡°ì ˆ

#### êµ¬í˜„ ì‚¬ì–‘

##### 1.1 ë‹¤ì¸µ í ì•„í‚¤í…ì²˜ ì¬ì„¤ê³„

**ëŒ€ìƒ íŒŒì¼**: `src/sensr_client.py`

**í˜„ì¬ êµ¬ì¡°**:
```python
# Line 36
self.message_queue = queue.Queue(maxsize=200)
```

**ìˆ˜ì • í›„**:
```python
import collections

class SensrClient:
    def __init__(self, config):
        # ê¸°ì¡´ ì½”ë“œ...

        # ë°ì´í„° íƒ€ì…ë³„ ë…ë¦½ ë²„í¼
        self.pointcloud_buffer = collections.deque(
            maxlen=config.get('queue.pointcloud_max', 500)
        )
        self.output_buffer = collections.deque(
            maxlen=config.get('queue.output_max', 200)
        )

        # ë©€í‹°í”„ë¡œì„¸ì‹± ì „ë‹¬ìš© í (mainì—ì„œ ì£¼ì…)
        self.processing_queue = None

        # ë°±í”„ë ˆì…” ì„¤ì •
        self.queue_config = {
            'max_items': config.get('queue.max_items', 500),
            'high_watermark_pct': config.get('queue.high_watermark_pct', 0.8),
            'drop_policy': config.get('queue.drop_policy', 'pointcloud_only')
        }

        # í†µê³„
        self.queue_stats = {
            'pointcloud_dropped': 0,
            'output_dropped': 0,
            'backpressure_events': 0,
            'total_received': 0
        }

    def set_processing_queue(self, queue):
        """ë©”ì¸ì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± í ì£¼ì…"""
        self.processing_queue = queue
```

**ê¸°ìˆ  ìŠ¤í™**:
- `collections.deque(maxlen=N)`:
  - O(1) append/pop ì—°ì‚°
  - maxlen ë„ë‹¬ ì‹œ ìë™ìœ¼ë¡œ ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
  - Thread-safe (GIL ë³´í˜¸)
- **íƒ€ì…ë³„ ë…ë¦½ ë²„í¼**:
  - `pointcloud_buffer`: 500ê°œ (í¬ê³  ì¤‘ìš”ë„ ë‚®ìŒ)
  - `output_buffer`: 200ê°œ (ì‘ê³  ì¤‘ìš”ë„ ë†’ìŒ)
- **ë°±í”„ë ˆì…” íŠ¸ë¦¬ê±°**: 80% ë„ë‹¬ ì‹œ ê²½ê³  1íšŒ, drop policy ì ìš©

##### 1.2 ìŠ¤ë§ˆíŠ¸ ë©”ì‹œì§€ íŒí”„

**ëŒ€ìƒ íŒŒì¼**: `src/sensr_client.py` (ì‹ ê·œ ë©”ì„œë“œ ì¶”ê°€)

```python
def start(self):
    """ê¸°ì¡´ start() ë©”ì„œë“œ ìˆ˜ì •"""
    # ê¸°ì¡´ WebSocket ì—°ê²° ì½”ë“œ...

    # ë©”ì‹œì§€ íŒí”„ ìŠ¤ë ˆë“œ ì‹œì‘
    self._start_message_pump()

def _start_message_pump(self):
    """ë°°ì¹˜ë¡œ ë©”ì‹œì§€ë¥¼ processing_queueë¡œ ì „ë‹¬"""
    self.pump_thread = threading.Thread(
        target=self._pump_worker,
        daemon=True,
        name="MessagePump"
    )
    self.pump_thread.start()
    self.logger.info("ë©”ì‹œì§€ íŒí”„ ìŠ¤ë ˆë“œ ì‹œì‘")

def _pump_worker(self):
    """
    ë°±í”„ë ˆì…” ì¸ì‹ íŒí”„ ì›Œì»¤
    - í ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§
    - ë°°ì¹˜ ì „ë‹¬ë¡œ ì˜¤ë²„í—¤ë“œ ê°ì†Œ
    - drop_policy ì ìš©
    """
    batch_size = self.queue_config.get('batch_size', 10)
    pump_interval = self.queue_config.get('pump_interval_ms', 50) / 1000.0

    while self.is_connected:
        batch = []

        # í˜„ì¬ í ì‚¬ìš©ë¥  ê³„ì‚°
        pc_usage = len(self.pointcloud_buffer) / self.queue_config['max_items']
        out_usage = len(self.output_buffer) / self.queue_config.get('output_max', 200)
        max_usage = max(pc_usage, out_usage)

        # ë°±í”„ë ˆì…” ì²´í¬
        if max_usage > self.queue_config['high_watermark_pct']:
            if self.queue_stats['backpressure_events'] == 0:
                self.logger.warning(
                    f"âš ï¸ í ì‚¬ìš©ë¥  {max_usage:.1%} ë„ë‹¬, ë°±í”„ë ˆì…” í™œì„±í™”"
                )
            self.queue_stats['backpressure_events'] += 1

            # Drop policy ì ìš©
            policy = self.queue_config['drop_policy']

            if policy == 'pointcloud_only':
                # output ë°ì´í„°ë§Œ ì „ë‹¬ (pointcloud ë“œë¡­)
                while self.output_buffer and len(batch) < batch_size:
                    batch.append(('output', self.output_buffer.popleft()))

                # pointcloud ë“œë¡­ ì¹´ìš´íŠ¸
                dropped = len(self.pointcloud_buffer)
                self.queue_stats['pointcloud_dropped'] += dropped
                self.pointcloud_buffer.clear()

            elif policy == 'output_only':
                # pointcloudë§Œ ì „ë‹¬ (output ë“œë¡­)
                while self.pointcloud_buffer and len(batch) < batch_size:
                    batch.append(('pointcloud', self.pointcloud_buffer.popleft()))

                dropped = len(self.output_buffer)
                self.queue_stats['output_dropped'] += dropped
                self.output_buffer.clear()

            elif policy == 'oldest':
                # ì˜¤ë˜ëœ ê²ƒë¶€í„° (dequeê°€ ìë™ ì²˜ë¦¬)
                pass

        # ì •ìƒ ëª¨ë“œ: ë‘˜ ë‹¤ ì „ë‹¬
        else:
            # pointcloud ìš°ì„ 
            while self.pointcloud_buffer and len(batch) < batch_size:
                batch.append(('pointcloud', self.pointcloud_buffer.popleft()))

            # output ë°ì´í„°
            while self.output_buffer and len(batch) < batch_size:
                batch.append(('output', self.output_buffer.popleft()))

        # ë°°ì¹˜ ì „ë‹¬
        if batch and self.processing_queue:
            for msg_type, msg_data in batch:
                try:
                    self.processing_queue.put(
                        {'type': msg_type, 'data': msg_data},
                        timeout=0.1
                    )
                except queue.Full:
                    self.logger.warning("Processing queue full, ë©”ì‹œì§€ ì¬ì‹œë„")
                    # ë‹¤ì‹œ ë²„í¼ì— ë„£ê¸°
                    if msg_type == 'pointcloud':
                        self.pointcloud_buffer.appendleft(msg_data)
                    else:
                        self.output_buffer.appendleft(msg_data)
                    break

        time.sleep(pump_interval)

def _on_pointcloud_message(self, ws, message):
    """ê¸°ì¡´ ì½œë°± ìˆ˜ì • - ë²„í¼ì—ë§Œ ì¶”ê°€"""
    try:
        self.pointcloud_buffer.append({
            'timestamp': time.time(),
            'data': message
        })
        self.queue_stats['total_received'] += 1
    except Exception as e:
        self.logger.error(f"í¬ì¸íŠ¸í´ë¼ìš°ë“œ ë²„í¼ ì—ëŸ¬: {e}")

def _on_output_message(self, ws, message):
    """ê¸°ì¡´ ì½œë°± ìˆ˜ì • - ë²„í¼ì—ë§Œ ì¶”ê°€"""
    try:
        self.output_buffer.append({
            'timestamp': time.time(),
            'data': message
        })
        self.queue_stats['total_received'] += 1
    except Exception as e:
        self.logger.error(f"Output ë²„í¼ ì—ëŸ¬: {e}")

def get_queue_status(self):
    """í ìƒíƒœ ì¡°íšŒ (ëª¨ë‹ˆí„°ë§ìš©)"""
    return {
        'pointcloud_size': len(self.pointcloud_buffer),
        'output_size': len(self.output_buffer),
        'pointcloud_usage': len(self.pointcloud_buffer) / self.queue_config['max_items'],
        'output_usage': len(self.output_buffer) / self.queue_config.get('output_max', 200),
        'stats': self.queue_stats.copy()
    }
```

**ê¸°ìˆ  ìŠ¤í™**:
- **ë°°ì¹˜ í¬ê¸°**: 10ê°œ (ì‹œìŠ¤í…œ ì½œ ì˜¤ë²„í—¤ë“œ 90% ê°ì†Œ)
- **íŒí”„ ì£¼ê¸°**: 50ms (1ì´ˆë‹¹ 20íšŒ ì²´í¬, ì‘ë‹µì„± ìœ ì§€)
- **ë™ì  policy**: ë°±í”„ë ˆì…” ì‹œ ì¤‘ìš” ë°ì´í„° ìš°ì„  ì „ë‹¬
- **ë¹„ë¸”ë¡œí‚¹**: WebSocket ì½œë°±ì´ í ëŒ€ê¸°ë¡œ ë¸”ë¡œí‚¹ë˜ì§€ ì•ŠìŒ

##### 1.3 ì„¤ì • íŒŒì¼ í™•ì¥

**ëŒ€ìƒ íŒŒì¼**: `config/config.yaml`

```yaml
# ============================================================
# í ê´€ë¦¬ ë° ë°±í”„ë ˆì…” (ì‹ ê·œ ì„¹ì…˜)
# ============================================================
queue:
  # í í¬ê¸°
  max_items: 500                    # pointcloud ë²„í¼ í¬ê¸°
  output_max: 200                   # output ë²„í¼ í¬ê¸°

  # ë°±í”„ë ˆì…” ì„¤ì •
  high_watermark_pct: 0.8           # 80% ë„ë‹¬ ì‹œ ë°±í”„ë ˆì…” í™œì„±í™”
  drop_policy: "pointcloud_only"    # ë“œë¡­ ì •ì±…
                                    #   - pointcloud_only: output ìš°ì„ , pointcloud ë“œë¡­
                                    #   - output_only: pointcloud ìš°ì„ , output ë“œë¡­
                                    #   - oldest: ì˜¤ë˜ëœ ê²ƒë¶€í„° ë“œë¡­ (FIFO)

  # ë°°ì¹˜ ì „ë‹¬
  batch_size: 10                    # í•œ ë²ˆì— ì „ë‹¬í•  ë©”ì‹œì§€ ìˆ˜
  pump_interval_ms: 50              # íŒí”„ ë™ì‘ ì£¼ê¸° (ë°€ë¦¬ì´ˆ)

# ëª¨ë‹ˆí„°ë§ (ì‹ ê·œ ì„¹ì…˜)
monitoring:
  queue_stats_interval: 5           # í í†µê³„ ë¡œê¹… ì£¼ê¸° (ì´ˆ)
  enable_detailed_stats: false      # ìƒì„¸ í†µê³„ í™œì„±í™” (ì„±ëŠ¥ ì˜í–¥)
```

##### 1.4 ë©€í‹°í”„ë¡œì„¸ì‹± í í¬ê¸° ì¡°ì •

**ëŒ€ìƒ íŒŒì¼**: `src/data_processor_multiprocessing.py`

**í˜„ì¬** (Lines 120-121):
```python
self.input_queue = mp.Queue(maxsize=100)
self.output_queue = mp.Queue(maxsize=1000)
```

**ìˆ˜ì • í›„**:
```python
self.input_queue = mp.Queue(
    maxsize=config.get('multiprocessing.input_queue_size', 500)
)
self.output_queue = mp.Queue(
    maxsize=config.get('multiprocessing.output_queue_size', 200)
)
```

**ì„¤ì • ì¶”ê°€** (`config/config.yaml`):
```yaml
multiprocessing:
  input_queue_size: 500   # 100 â†’ 500 (5ë°° ì¦ê°€)
  output_queue_size: 200  # 1000 â†’ 200 (ë©”ëª¨ë¦¬ ì ˆì•½, ì²˜ë¦¬ ì†ë„ í–¥ìƒ í›„ ì¶©ë¶„)
  num_workers: 4          # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìˆ˜
```

##### 1.5 Bag Writer í í™•ì¥

**ëŒ€ìƒ íŒŒì¼**: `test/src/bag_recorder_optimized.py`

**í˜„ì¬** (Line 58):
```python
self.message_queue = queue.Queue(maxsize=50)
```

**ìˆ˜ì • í›„**:
```python
self.message_queue = queue.Queue(
    maxsize=config.get('bag_writer.queue_size', 200)
)
```

**ì„¤ì • ì¶”ê°€** (`config/config.yaml`):
```yaml
bag_writer:
  queue_size: 200         # 50 â†’ 200 (4ë°° ì¦ê°€)
  batch_size: 20          # ë°°ì¹˜ ì“°ê¸° í¬ê¸° (ë‹¤ìŒ Priorityì—ì„œ êµ¬í˜„)
  flush_interval_ms: 100  # ë°°ì¹˜ í”ŒëŸ¬ì‹œ ì£¼ê¸°
```

#### ê²€ì¦ ê¸°ì¤€ (Acceptance Criteria)

| ë²ˆí˜¸ | ê¸°ì¤€ | ì¸¡ì • ë°©ë²• | ëª©í‘œ |
|------|------|----------|------|
| 1 | **60ì´ˆ í…ŒìŠ¤íŠ¸ ì™„ì£¼** | `run_multiprocessing_wsl.sh` ì‹¤í–‰ | ì¤‘ë‹¨ ì—†ì´ 60ì´ˆ ì™„ë£Œ |
| 2 | **ë©”ì‹œì§€ ë“œë¡­ <5%** | `stats['dropped'] / stats['received']` | <0.05 |
| 3 | **í ê²½ê³  ì œê±°** | ë¡œê·¸ì—ì„œ "ë©”ì‹œì§€ íê°€ ê°€ë“ì°¸" ê²€ìƒ‰ | 0íšŒ (ë°±í”„ë ˆì…” ê²½ê³  1íšŒ í—ˆìš©) |
| 4 | **í ì‚¬ìš©ë¥ ** | `queue_size / max_items` | <0.8 ìœ ì§€ |
| 5 | **ë°±í”„ë ˆì…” íš¨ê³¼** | ë°±í”„ë ˆì…” í™œì„±í™” ì‹œ output ë°ì´í„° ì „ë‹¬ë¥  | 100% |

---

### Priority 2: ì²˜ë¦¬ ë³‘ëª© í•´ì†Œ

#### ëª©í‘œ
- âœ… ì²˜ë¦¬ìœ¨ 1.4 msg/s â†’ **8 msg/s** (5.7ë°° ê°œì„ )
- âœ… í‰ê·  ì²˜ë¦¬ ì‹œê°„ 329ms â†’ **125ms** (2.6ë°° ê°œì„ )
- âœ… ì›Œì»¤ íš¨ìœ¨ì„± í–¥ìƒ (CPU í™œìš©ë¥  ì¦ê°€)

#### êµ¬í˜„ ì‚¬ì–‘

##### 2.1 ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ 3ë‹¨ê³„ ë¶„ë¦¬

**í˜„ì¬ ì•„í‚¤í…ì²˜**:
```
[Worker 1] Protobuf íŒŒì‹± â†’ NumPy ë³€í™˜ â†’ ROS ë©”ì‹œì§€ ìƒì„± (329ms)
[Worker 2] Protobuf íŒŒì‹± â†’ NumPy ë³€í™˜ â†’ ROS ë©”ì‹œì§€ ìƒì„± (329ms)
[Worker 3] Protobuf íŒŒì‹± â†’ NumPy ë³€í™˜ â†’ ROS ë©”ì‹œì§€ ìƒì„± (329ms)
[Worker 4] Protobuf íŒŒì‹± â†’ NumPy ë³€í™˜ â†’ ROS ë©”ì‹œì§€ ìƒì„± (329ms)
              â†“
       [Bag Writer] ì§ë ¬í™” + ë””ìŠ¤í¬ ì“°ê¸°

ì´ë¡  ì²˜ë¦¬ëŸ‰: 4 Ã— (1/0.329) = 12.1 msg/s
ì‹¤ì œ ë‹¬ì„±: 1.4 msg/s (íš¨ìœ¨ì„± 11.6%)
```

**ë¬¸ì œì **:
- ROS ë©”ì‹œì§€ ìƒì„±(150ms)ì´ ê° ì›Œì»¤ë¥¼ ë¸”ë¡œí‚¹
- GIL ê²½í•©ìœ¼ë¡œ ë³‘ë ¬í™” íš¨ìœ¨ ì €í•˜
- ë©”ëª¨ë¦¬ ë³µì‚¬ ì˜¤ë²„í—¤ë“œ (vstack, hstack, tobytes)

**ìˆ˜ì • í›„ ì•„í‚¤í…ì²˜**:
```
Phase 1: Protobuf â†’ NumPy (CPU ì§‘ì•½ì , ë©€í‹°í”„ë¡œì„¸ì‹±)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Worker 1-4] Protobuf íŒŒì‹± (25ms)              â”‚
â”‚              NumPy ë³€í™˜ (100ms)                 â”‚
â”‚              = 125ms per message                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ numpy_queue (NumPy ë°°ì—´)

Phase 2: NumPy â†’ ROS2 ë©”ì‹œì§€ (I/O ëŒ€ê¸°, ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [ROS Builder] ROS ë©”ì‹œì§€ ìƒì„± (150ms)          â”‚
â”‚               (I/O ëŒ€ê¸° ì¤‘ GIL í•´ì œ)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ output_queue (ROS ë©”ì‹œì§€)

Phase 3: ROS2 ë©”ì‹œì§€ â†’ ë””ìŠ¤í¬ (I/O, ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Bag Writer] ë°°ì¹˜ ì§ë ¬í™” + ë¹„ë™ê¸° ì“°ê¸°         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì´ë¡  ì²˜ë¦¬ëŸ‰:
  Phase 1: 4 Ã— (1/0.125) = 32 msg/s
  Phase 2: 1 Ã— (1/0.150) = 6.7 msg/s  â† ë³‘ëª©
  Phase 3: 1 Ã— (1/0.020) = 50 msg/s (ë°°ì¹˜ ì“°ê¸° í›„)

ì´ ì²˜ë¦¬ëŸ‰: min(32, 6.7, 50) = 6.7 msg/s
ì‹¤ì œ ì˜ˆìƒ: ~6-8 msg/s (ì˜¤ë²„í—¤ë“œ ê°ì•ˆ)
```

**ëŒ€ìƒ íŒŒì¼**: `src/data_processor_multiprocessing.py` (ëŒ€ëŒ€ì  ìˆ˜ì •)

```python
import multiprocessing as mp
import queue
import time
import logging

def _worker_process_protobuf_only(input_queue, numpy_queue, config, worker_id, shutdown_event):
    """
    Phase 1 Worker: Protobuf â†’ NumPyë§Œ ìˆ˜í–‰
    ê°€ì¥ CPU ì§‘ì•½ì ì¸ ë¶€ë¶„ë§Œ ë©€í‹°í”„ë¡œì„¸ì‹±

    Args:
        input_queue: Raw protobuf ë©”ì‹œì§€ í
        numpy_queue: NumPy ë°°ì—´ ì¶œë ¥ í
        config: ì„¤ì •
        worker_id: ì›Œì»¤ ID
        shutdown_event: ì¢…ë£Œ ì´ë²¤íŠ¸
    """
    logger = logging.getLogger(f"worker_{worker_id}")

    try:
        # DataProcessor ì´ˆê¸°í™” (ê° ì›Œì»¤ë§ˆë‹¤)
        from src.data_processor import DataProcessor
        processor = DataProcessor(config)
        logger.info(f"ğŸ”§ ì›Œì»¤ {worker_id} ì‹œì‘")

        while not shutdown_event.is_set():
            try:
                # ì§§ì€ íƒ€ì„ì•„ì›ƒ (shutdown_event ìì£¼ ì²´í¬)
                message_data = input_queue.get(timeout=0.5)

                # None = ì¢…ë£Œ ì‹ í˜¸
                if message_data is None:
                    logger.info(f"ì›Œì»¤ {worker_id}: ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
                    break

                start_time = time.time()

                # íƒ€ì…ë³„ ì²˜ë¦¬
                if message_data['type'] == 'pointcloud':
                    # Protobuf íŒŒì‹± + NumPy ë³€í™˜ (125ms)
                    points, intensities = processor._decode_pointcloud_protobuf(
                        message_data['data']
                    )

                    result = {
                        'type': 'pointcloud',
                        'timestamp': message_data['timestamp'],
                        'points': points,          # NumPy array
                        'intensities': intensities, # NumPy array
                        'processing_time': (time.time() - start_time) * 1000
                    }

                elif message_data['type'] == 'output':
                    # Output ë°ì´í„°ëŠ” ë³€í™˜ ë¶ˆí•„ìš”, ê·¸ëŒ€ë¡œ ì „ë‹¬
                    result = {
                        'type': 'output',
                        'timestamp': message_data['timestamp'],
                        'data': message_data['data'],
                        'processing_time': (time.time() - start_time) * 1000
                    }
                else:
                    logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_data['type']}")
                    continue

                # NumPy íë¡œ ì „ë‹¬
                numpy_queue.put(result, timeout=1.0)

            except queue.Empty:
                continue
            except queue.Full:
                logger.warning(f"ì›Œì»¤ {worker_id}: NumPy í ê°€ë“ì°¸, ì¬ì‹œë„")
                time.sleep(0.1)
            except Exception as e:
                logger.error(f"ì›Œì»¤ {worker_id} ì²˜ë¦¬ ì—ëŸ¬: {e}", exc_info=True)

        logger.info(f"âœ… ì›Œì»¤ {worker_id} ì •ìƒ ì¢…ë£Œ")

    except KeyboardInterrupt:
        logger.info(f"ì›Œì»¤ {worker_id}: KeyboardInterrupt")
    except Exception as e:
        logger.error(f"ì›Œì»¤ {worker_id} ì¹˜ëª…ì  ì—ëŸ¬: {e}", exc_info=True)
    finally:
        logger.info(f"ì›Œì»¤ {worker_id}: ì •ë¦¬ ì™„ë£Œ")


def _ros_builder_process(numpy_queue, output_queue, config, shutdown_event):
    """
    Phase 2 Worker: NumPy â†’ ROS2 ë©”ì‹œì§€ ë³€í™˜ (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤)
    I/O ëŒ€ê¸° ì¤‘ GIL í•´ì œë˜ë¯€ë¡œ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ ì¶©ë¶„

    Args:
        numpy_queue: NumPy ë°°ì—´ ì…ë ¥ í
        output_queue: ROS ë©”ì‹œì§€ ì¶œë ¥ í
        config: ì„¤ì •
        shutdown_event: ì¢…ë£Œ ì´ë²¤íŠ¸
    """
    logger = logging.getLogger("ros_builder")

    try:
        from src.data_processor import DataProcessor
        processor = DataProcessor(config)
        logger.info("ğŸ”§ ROS Builder ì‹œì‘")

        while not shutdown_event.is_set():
            try:
                result = numpy_queue.get(timeout=0.5)

                if result is None:
                    logger.info("ROS Builder: ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
                    break

                start_time = time.time()

                if result['type'] == 'pointcloud':
                    # ROS2 PointCloud2 ë©”ì‹œì§€ ìƒì„±
                    msg = processor._create_pointcloud2_message(
                        {
                            'points': result['points'],
                            'intensities': result['intensities']
                        },
                        result['timestamp']
                    )

                    ros_result = {
                        'type': 'pointcloud',
                        'topic': '/sensr/pointcloud',
                        'message': msg,
                        'timestamp': result['timestamp'],
                        'phase1_time': result['processing_time'],
                        'phase2_time': (time.time() - start_time) * 1000
                    }

                elif result['type'] == 'output':
                    # Output ë°ì´í„° ë©”ì‹œì§€ ìƒì„±
                    msg = processor._create_output_message(result['data'])

                    ros_result = {
                        'type': 'output',
                        'topic': '/sensr/output',
                        'message': msg,
                        'timestamp': result['timestamp'],
                        'phase1_time': result['processing_time'],
                        'phase2_time': (time.time() - start_time) * 1000
                    }
                else:
                    continue

                output_queue.put(ros_result, timeout=1.0)

            except queue.Empty:
                continue
            except queue.Full:
                logger.warning("ROS Builder: Output í ê°€ë“ì°¸, ì¬ì‹œë„")
                time.sleep(0.1)
            except Exception as e:
                logger.error(f"ROS Builder ì²˜ë¦¬ ì—ëŸ¬: {e}", exc_info=True)

        logger.info("âœ… ROS Builder ì •ìƒ ì¢…ë£Œ")

    except KeyboardInterrupt:
        logger.info("ROS Builder: KeyboardInterrupt")
    except Exception as e:
        logger.error(f"ROS Builder ì¹˜ëª…ì  ì—ëŸ¬: {e}", exc_info=True)
    finally:
        logger.info("ROS Builder: ì •ë¦¬ ì™„ë£Œ")


class DataProcessorMultiprocessing:
    """3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ë©€í‹°í”„ë¡œì„¸ì‹± ì²˜ë¦¬ê¸°"""

    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)

        # ì›Œì»¤ ì„¤ì •
        self.num_workers = config.get('multiprocessing.num_workers', 4)

        # 3ë‹¨ê³„ í ì‹œìŠ¤í…œ
        self.input_queue = mp.Queue(
            maxsize=config.get('multiprocessing.input_queue_size', 500)
        )
        self.numpy_queue = mp.Queue(
            maxsize=config.get('multiprocessing.numpy_queue_size', 200)
        )
        self.output_queue = mp.Queue(
            maxsize=config.get('multiprocessing.output_queue_size', 200)
        )

        # ì¢…ë£Œ ì´ë²¤íŠ¸
        self.shutdown_event = mp.Event()

        # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤
        self.workers = []
        self.ros_builder = None

        # í†µê³„
        self.stats = {
            'total_processed': 0,
            'total_dropped': 0,
            'phase1_times': [],
            'phase2_times': [],
        }

        self.is_running = False

    def start(self):
        """ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘"""
        self.logger.info(f"ğŸš€ ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘: {self.num_workers}ê°œ ì›Œì»¤")

        # Phase 1 ì›Œì»¤ë“¤ ì‹œì‘ (Protobuf â†’ NumPy)
        for i in range(self.num_workers):
            worker = mp.Process(
                target=_worker_process_protobuf_only,
                args=(
                    self.input_queue,
                    self.numpy_queue,
                    self.config,
                    i,
                    self.shutdown_event
                ),
                name=f"Worker-{i}"
            )
            worker.start()
            self.workers.append(worker)
            self.logger.info(f"  - ì›Œì»¤ {i} ì‹œì‘ (PID: {worker.pid})")

        # Phase 2 ì›Œì»¤ ì‹œì‘ (NumPy â†’ ROS) - ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤
        self.ros_builder = mp.Process(
            target=_ros_builder_process,
            args=(
                self.numpy_queue,
                self.output_queue,
                self.config,
                self.shutdown_event
            ),
            name="ROS-Builder"
        )
        self.ros_builder.start()
        self.logger.info(f"  - ROS Builder ì‹œì‘ (PID: {self.ros_builder.pid})")

        self.is_running = True
        self.logger.info("âœ… ë©€í‹°í”„ë¡œì„¸ì‹± ì´ˆê¸°í™” ì™„ë£Œ")

    def process_message(self, message_data):
        """
        ë©”ì‹œì§€ ì²˜ë¦¬ (ë¹„ë™ê¸°)

        Args:
            message_data: {'type': 'pointcloud' or 'output', 'data': ..., 'timestamp': ...}

        Returns:
            None (ë¹„ë™ê¸° ì²˜ë¦¬)
        """
        try:
            self.input_queue.put_nowait(message_data)
            return None
        except queue.Full:
            self.stats['total_dropped'] += 1
            self.logger.warning("Input í ê°€ë“ì°¸, ë©”ì‹œì§€ ë“œë¡­")
            return None

    def get_results(self, timeout=0.1, max_results=10):
        """
        ì²˜ë¦¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ë°°ì¹˜)

        Args:
            timeout: ëŒ€ê¸° ì‹œê°„
            max_results: ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜

        Returns:
            List[dict]: ì²˜ë¦¬ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        results = []

        for _ in range(max_results):
            try:
                result = self.output_queue.get(timeout=timeout)
                results.append(result)
                self.stats['total_processed'] += 1

                # í†µê³„ ìˆ˜ì§‘
                if 'phase1_time' in result:
                    self.stats['phase1_times'].append(result['phase1_time'])
                if 'phase2_time' in result:
                    self.stats['phase2_times'].append(result['phase2_time'])

            except queue.Empty:
                break

        return results

    def stop(self):
        """ì •ìƒ ì¢…ë£Œ"""
        self.logger.info("ë©€í‹°í”„ë¡œì„¸ì‹± ì¢…ë£Œ ì‹œì‘...")
        start_time = time.time()

        # 1ë‹¨ê³„: ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
        self.shutdown_event.set()

        self.logger.info(f"  - {len(self.workers)}ê°œ ì›Œì»¤ì— ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡")
        for _ in range(len(self.workers)):
            try:
                self.input_queue.put(None, timeout=1.0)
            except queue.Full:
                self.logger.warning("  - ì…ë ¥ í ê°€ë“ì°¸")

        # ROS builderì—ë„ ì¢…ë£Œ ì‹ í˜¸
        if self.ros_builder:
            try:
                self.numpy_queue.put(None, timeout=1.0)
            except queue.Full:
                pass

        # 2ë‹¨ê³„: ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°
        timeout_per_worker = 5
        for i, worker in enumerate(self.workers):
            worker.join(timeout=timeout_per_worker)

            if worker.is_alive():
                self.logger.warning(f"  - ì›Œì»¤ {i} ì‘ë‹µ ì—†ìŒ, ê°•ì œ ì¢…ë£Œ")
                worker.terminate()
                worker.join(timeout=1.0)
            else:
                self.logger.info(f"  - ì›Œì»¤ {i} ì •ìƒ ì¢…ë£Œ")

        # ROS builder ì¢…ë£Œ
        if self.ros_builder:
            self.ros_builder.join(timeout=timeout_per_worker)
            if self.ros_builder.is_alive():
                self.logger.warning("  - ROS builder ê°•ì œ ì¢…ë£Œ")
                self.ros_builder.terminate()
            else:
                self.logger.info("  - ROS builder ì •ìƒ ì¢…ë£Œ")

        # 3ë‹¨ê³„: í ë“œë ˆì´ë‹
        remaining_in = self.input_queue.qsize()
        remaining_numpy = self.numpy_queue.qsize()
        remaining_out = self.output_queue.qsize()

        if remaining_in + remaining_numpy + remaining_out > 0:
            self.logger.warning(
                f"  - ë¯¸ì²˜ë¦¬ ë©”ì‹œì§€: input={remaining_in}, "
                f"numpy={remaining_numpy}, output={remaining_out}"
            )

        self.is_running = False
        elapsed = time.time() - start_time
        self.logger.info(f"ë©€í‹°í”„ë¡œì„¸ì‹± ì¢…ë£Œ ì™„ë£Œ ({elapsed:.1f}ì´ˆ)")

    def get_stats(self):
        """í†µê³„ ì¡°íšŒ"""
        import numpy as np

        stats = self.stats.copy()

        if self.stats['phase1_times']:
            stats['phase1_avg'] = np.mean(self.stats['phase1_times'][-100:])
            stats['phase1_min'] = np.min(self.stats['phase1_times'][-100:])
            stats['phase1_max'] = np.max(self.stats['phase1_times'][-100:])

        if self.stats['phase2_times']:
            stats['phase2_avg'] = np.mean(self.stats['phase2_times'][-100:])
            stats['phase2_min'] = np.min(self.stats['phase2_times'][-100:])
            stats['phase2_max'] = np.max(self.stats['phase2_times'][-100:])

        return stats
```

**ì„¤ì • ì¶”ê°€** (`config/config.yaml`):
```yaml
multiprocessing:
  num_workers: 4                    # Phase 1 ì›Œì»¤ ìˆ˜
  input_queue_size: 500             # Raw protobuf í
  numpy_queue_size: 200             # NumPy ë°°ì—´ í
  output_queue_size: 200            # ROS ë©”ì‹œì§€ í
```

**ê¸°ìˆ  ìŠ¤í™**:
- **Phase 1** (4 workers): Protobuf íŒŒì‹±(25ms) + NumPy ë³€í™˜(100ms) = 125ms
  - ì´ë¡  ì²˜ë¦¬ëŸ‰: 4 Ã— (1/0.125) = **32 msg/s**
- **Phase 2** (1 worker): ROS ë©”ì‹œì§€ ìƒì„±(150ms)
  - ì´ë¡  ì²˜ë¦¬ëŸ‰: 1 Ã— (1/0.150) = **6.7 msg/s** â† **ë³‘ëª©**
- **ì´ ì²˜ë¦¬ëŸ‰**: min(32, 6.7) = **6.7 msg/s** (í˜„ì¬ 1.4 â†’ **4.8ë°° ê°œì„ **)

##### 2.2 ì„±ëŠ¥ ê³„ì¸¡ ì‹œìŠ¤í…œ

**ëŒ€ìƒ íŒŒì¼**: `test/main_multiprocessing.py` (ìˆ˜ì •)

```python
class SensrMultiprocessingApp:
    def __init__(self, config, test_duration=None):
        # ê¸°ì¡´ ì½”ë“œ...

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
        self.monitor_thread = None

    def run(self):
        # ê¸°ì¡´ ì½”ë“œ...

        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self._start_monitoring()

        # ë©”ì¸ ë£¨í”„...

    def _start_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘"""
        self.monitor_thread = threading.Thread(
            target=self._monitor_performance,
            daemon=True,
            name="PerfMonitor"
        )
        self.monitor_thread.start()

    def _monitor_performance(self):
        """ì£¼ê¸°ì  ì„±ëŠ¥ ë¡œê¹…"""
        interval = self.config.get('monitoring.perf_metrics_interval', 10)

        while self.is_running:
            time.sleep(interval)

            # ë©€í‹°í”„ë¡œì„¸ì‹± í†µê³„
            mp_stats = self.processor.get_stats()

            # í ìƒíƒœ
            queue_status = self.client.get_queue_status()

            # ë¡œê¹…
            self.logger.info("="*70)
            self.logger.info("â±ï¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ìµœê·¼ 10ì´ˆ)")
            self.logger.info(f"  - Phase1 í‰ê· : {mp_stats.get('phase1_avg', 0):.1f}ms")
            self.logger.info(f"  - Phase2 í‰ê· : {mp_stats.get('phase2_avg', 0):.1f}ms")
            self.logger.info(f"  - ì´ ì²˜ë¦¬ ì‹œê°„: {mp_stats.get('phase1_avg', 0) + mp_stats.get('phase2_avg', 0):.1f}ms")
            self.logger.info(f"  - ì²˜ë¦¬ëŸ‰: {mp_stats['total_processed'] / interval:.1f} msg/s")
            self.logger.info("ğŸ“Š í ìƒíƒœ")
            self.logger.info(f"  - Pointcloud: {queue_status['pointcloud_size']} ({queue_status['pointcloud_usage']:.1%})")
            self.logger.info(f"  - Output: {queue_status['output_size']} ({queue_status['output_usage']:.1%})")
            self.logger.info(f"  - Input Queue: {self.processor.input_queue.qsize()}")
            self.logger.info(f"  - NumPy Queue: {self.processor.numpy_queue.qsize()}")
            self.logger.info(f"  - Output Queue: {self.processor.output_queue.qsize()}")
            self.logger.info("="*70)
```

#### ê²€ì¦ ê¸°ì¤€ (Acceptance Criteria)

| ë²ˆí˜¸ | ê¸°ì¤€ | ì¸¡ì • ë°©ë²• | ëª©í‘œ |
|------|------|----------|------|
| 1 | **ì²˜ë¦¬ìœ¨ â‰¥8 msg/s** | 60ì´ˆ í…ŒìŠ¤íŠ¸ì—ì„œ ì²˜ë¦¬ ë©”ì‹œì§€ ìˆ˜ / 60 | â‰¥8 msg/s |
| 2 | **í‰ê·  ì²˜ë¦¬ ì‹œê°„ <150ms** | Phase1 + Phase2 í‰ê·  | <150ms |
| 3 | **ì›Œì»¤ íš¨ìœ¨ì„± >60%** | ì‹¤ì œ ì²˜ë¦¬ìœ¨ / ì´ë¡  ì²˜ë¦¬ìœ¨ | >0.6 |
| 4 | **í ê¹Šì´ ì•ˆì •** | input_queue.qsize() | <200 |
| 5 | **NumPy í ì•ˆì •** | numpy_queue.qsize() | <100 |

---

### Priority 3: ë””ìŠ¤í¬ ì“°ê¸° ìµœì í™”

#### ëª©í‘œ
- âœ… ì“°ê¸° ì†ë„ 2.3 msg/s â†’ **10 msg/s** (4.3ë°° ê°œì„ )
- âœ… ë°°ì¹˜ ì“°ê¸°ë¡œ I/O íšŸìˆ˜ 90% ê°ì†Œ
- âœ… ë¹„ë™ê¸° ì“°ê¸°ë¡œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ê³¼ ë¶„ë¦¬

#### êµ¬í˜„ ì‚¬ì–‘

##### 3.1 ë°°ì¹˜ ì“°ê¸° í™œì„±í™”

**ëŒ€ìƒ íŒŒì¼**: `test/src/bag_recorder_optimized.py`

**í˜„ì¬ ë¬¸ì œ** (Lines 255-335):
```python
def _recording_worker(self):
    while self.is_recording:
        message_data = self.message_queue.get(timeout=1.0)

        # ì¦‰ì‹œ ë‹¨ì¼ ì“°ê¸° (~400ms)
        serialized_msg = serialize_message(message_data['message'])
        self.current_writer.write(topic_name, serialized_msg, ros_time_ns)
```

**ìˆ˜ì •**:
```python
class BagRecorderOptimized:
    def __init__(self, config):
        # ê¸°ì¡´ ì½”ë“œ...

        # ë°°ì¹˜ ì„¤ì •
        self.batch_config = {
            'enable_batching': config.get('bag_writer.enable_batching', True),
            'batch_size': config.get('bag_writer.batch_size', 20),
            'flush_interval': config.get('bag_writer.flush_interval_ms', 100) / 1000.0,
        }

        # ë°°ì¹˜ ë²„í¼
        self.batch_buffer = []
        self.last_flush_time = time.time()

    def _recording_worker(self):
        """ë°°ì¹˜ ê¸°ë°˜ ë ˆì½”ë”© ì›Œì»¤"""
        while self.is_recording:
            try:
                message_data = self.message_queue.get(timeout=0.1)

                if self.batch_config['enable_batching']:
                    self.batch_buffer.append(message_data)

                    # ë°°ì¹˜ í”ŒëŸ¬ì‹œ ì¡°ê±´
                    should_flush = (
                        len(self.batch_buffer) >= self.batch_config['batch_size']
                        or (time.time() - self.last_flush_time) >= self.batch_config['flush_interval']
                    )

                    if should_flush:
                        self._flush_batch()
                else:
                    # ë ˆê±°ì‹œ ë‹¨ì¼ ì“°ê¸°
                    self._write_single_message(message_data)

            except queue.Empty:
                # íƒ€ì„ì•„ì›ƒ: ë²„í¼ì— ë°ì´í„° ìˆìœ¼ë©´ í”ŒëŸ¬ì‹œ
                if self.batch_buffer:
                    self._flush_batch()
                continue
            except Exception as e:
                self.logger.error(f"ë ˆì½”ë”© ì›Œì»¤ ì—ëŸ¬: {e}", exc_info=True)

    def _flush_batch(self):
        """ë°°ì¹˜ ë²„í¼ë¥¼ í•œ ë²ˆì— ë””ìŠ¤í¬ì— ì“°ê¸°"""
        if not self.batch_buffer:
            return

        start_time = time.time()
        batch_size = len(self.batch_buffer)

        try:
            for message_data in self.batch_buffer:
                topic_name = self._get_topic_name(message_data)

                # í† í”½ ìƒì„± (ì²« ë©”ì‹œì§€ë§Œ)
                if topic_name not in self.created_topics:
                    self._create_topic(message_data)

                # ì§ë ¬í™” + ì“°ê¸°
                serialized_msg = serialize_message(message_data['message'])
                ros_time_ns = self._to_ros_time(message_data['timestamp'])
                self.current_writer.write(topic_name, serialized_msg, ros_time_ns)

            flush_time = (time.time() - start_time) * 1000
            avg_time = flush_time / batch_size

            self.logger.debug(
                f"ğŸ’¾ ë°°ì¹˜ í”ŒëŸ¬ì‹œ: {batch_size}ê°œ, {flush_time:.1f}ms "
                f"({avg_time:.1f}ms/msg)"
            )

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['total_writes'] += batch_size
            self.stats['total_flush_time'] += flush_time

        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ í”ŒëŸ¬ì‹œ ì‹¤íŒ¨: {e}", exc_info=True)
            self.stats['total_dropped'] += batch_size
        finally:
            self.batch_buffer.clear()
            self.last_flush_time = time.time()
```

**ì„¤ì •** (`config/config.yaml`):
```yaml
bag_writer:
  queue_size: 200
  enable_batching: true       # ë°°ì¹˜ ì“°ê¸° í™œì„±í™”
  batch_size: 20              # 20ê°œì”© ë°°ì¹˜
  flush_interval_ms: 100      # 100ms ë‚´ í”ŒëŸ¬ì‹œ
```

**ì„±ëŠ¥ ì˜ˆì¸¡**:
```
ë‹¨ì¼ ì“°ê¸°:
  400ms per message
  ì²˜ë¦¬ëŸ‰: 1 / 0.4 = 2.5 msg/s

ë°°ì¹˜ ì“°ê¸° (20ê°œ):
  íŠ¸ëœì­ì…˜ ì˜¤ë²„í—¤ë“œ: ~200ms (ê³ ì •)
  ì§ë ¬í™”: 150ms Ã— 20 = 3000ms
  ì´: 3200ms for 20 messages
  í‰ê· : 3200 / 20 = 160ms per message

  ê·¸ëŸ¬ë‚˜ íŒŒì´í”„ë¼ì¸ íš¨ê³¼:
    - ë‹¤ìŒ ë°°ì¹˜ ì¤€ë¹„ ì¤‘ ë””ìŠ¤í¬ ì“°ê¸°
    - ì‹¤ì œ ì²˜ë¦¬ëŸ‰: ~400ms for 20 messages
    - í‰ê· : 20ms per message
    - ì²˜ë¦¬ëŸ‰: 1 / 0.02 = 50 msg/s
```

##### 3.2 SQLite3 WAL ëª¨ë“œ ìµœì í™”

**ëŒ€ìƒ íŒŒì¼**: `test/src/bag_recorder_optimized.py`

```python
from rosbag2_py import StorageOptions, ConverterOptions

class BagRecorderOptimized:
    def _open_bag(self):
        """Bag íŒŒì¼ ì—´ê¸° (SQLite3 ìµœì í™” ì ìš©)"""
        # ì¶œë ¥ ê²½ë¡œ
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(
            self.output_directory,
            f"sensr_data_{timestamp}"
        )

        # Storage ì˜µì…˜
        storage_options = StorageOptions(
            uri=output_path,
            storage_id='sqlite3'
        )

        # SQLite3 ìµœì í™” ì„¤ì •
        # https://www.sqlite.org/pragma.html
        optimization = [
            "journal_mode=WAL",        # Write-Ahead Logging
            "synchronous=NORMAL",      # FULL â†’ NORMAL (ì„±ëŠ¥ â†‘)
            "cache_size=10000",        # 10MB ìºì‹œ (ê¸°ë³¸ 2MB)
            "page_size=4096",          # í˜ì´ì§€ í¬ê¸°
            "temp_store=MEMORY",       # ì„ì‹œ ì €ì¥ì†Œ ë©”ëª¨ë¦¬
            "locking_mode=EXCLUSIVE"   # ë°°íƒ€ì  ì ê¸ˆ (ë‹¨ì¼ writer)
        ]
        storage_options.storage_config_uri = ";".join(optimization)

        # Converter ì˜µì…˜
        converter_options = ConverterOptions(
            input_serialization_format='cdr',
            output_serialization_format='cdr'
        )

        # Writer ì—´ê¸°
        self.current_writer = SequentialWriter()
        self.current_writer.open(storage_options, converter_options)

        self.logger.info(f"ğŸ“ Bag íŒŒì¼ ì—´ê¸°: {output_path}")
        self.logger.info(f"ğŸ”§ SQLite3 ìµœì í™”: {', '.join(optimization)}")
```

**ìµœì í™” íš¨ê³¼**:
```
journal_mode=WAL:
  - ì½ê¸°ì™€ ì“°ê¸° ë™ì‹œ ê°€ëŠ¥
  - fsync íšŸìˆ˜ ê°ì†Œ
  - ì„±ëŠ¥ í–¥ìƒ: 20-30%

synchronous=NORMAL:
  - FULL: ëª¨ë“  ì“°ê¸° í›„ fsync (ì•ˆì „, ëŠë¦¼)
  - NORMAL: ì¤‘ìš” ì‹œì ë§Œ fsync (ë¹ ë¦„, ì•ˆì „)
  - OFF: fsync ì•ˆ í•¨ (ë§¤ìš° ë¹ ë¦„, ìœ„í—˜)
  - ì„±ëŠ¥ í–¥ìƒ: 30-50%

cache_size=10000:
  - ê¸°ë³¸ 2MB â†’ 10MB
  - ë©”ëª¨ë¦¬ ìºì‹±ìœ¼ë¡œ ë””ìŠ¤í¬ I/O ê°ì†Œ
  - ì„±ëŠ¥ í–¥ìƒ: 10-20%

ì´ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 50-70%
  2.3 msg/s â†’ 3.5-4.0 msg/s
```

#### ê²€ì¦ ê¸°ì¤€ (Acceptance Criteria)

| ë²ˆí˜¸ | ê¸°ì¤€ | ì¸¡ì • ë°©ë²• | ëª©í‘œ |
|------|------|----------|------|
| 1 | **ì“°ê¸° ì†ë„ â‰¥10 msg/s** | 60ì´ˆ í…ŒìŠ¤íŠ¸ ì“°ê¸° ìˆ˜ / 60 | â‰¥10 msg/s |
| 2 | **í‰ê·  ì“°ê¸° ì‹œê°„ <100ms** | ë°°ì¹˜ ì‹œê°„ / ë°°ì¹˜ í¬ê¸° | <100ms |
| 3 | **ë°°ì¹˜ íš¨ìœ¨ì„± >90%** | ë°°ì¹˜ ë©”ì‹œì§€ ìˆ˜ / ì „ì²´ | >0.9 |
| 4 | **í ì•ˆì •ì„±** | bag_recorder.message_queue.qsize() | <100 |
| 5 | **ë°ì´í„° ë¬´ê²°ì„±** | `ros2 bag info` ê²€ì¦ | PASS |

---

### Priority 4: ì •ìƒ ì¢…ë£Œ êµ¬í˜„

#### ëª©í‘œ
- âœ… Ctrl+C ì‹œ SystemExit ì˜ˆì™¸ ì œê±°
- âœ… ëª¨ë“  ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì •ìƒ ì¢…ë£Œ
- âœ… í ë‚´ ë°ì´í„° ì†ì‹¤ ì—†ì´ í”ŒëŸ¬ì‹œ
- âœ… ìµœì¢… ë¦¬í¬íŠ¸ ì •ìƒ ì¶œë ¥

#### êµ¬í˜„ ì‚¬ì–‘

##### 4.1 ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë¦¬íŒ©í† ë§

**ëŒ€ìƒ íŒŒì¼**: `src/utils.py`

**í˜„ì¬** (Lines 217-234):
```python
def create_signal_handler(cleanup_func):
    def signal_handler(sig, frame):
        print(f"\nì‹œê·¸ë„ {sig} ìˆ˜ì‹ . í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤...")
        if cleanup_func:
            cleanup_func()
        sys.exit(0)  # âš ï¸ SystemExit ë°œìƒ!
    return signal_handler
```

**ìˆ˜ì •**:
```python
import multiprocessing as mp
import signal

def create_signal_handler(shutdown_event: mp.Event, cleanup_func=None):
    """
    SystemExit ì—†ì´ ì •ìƒ ì¢…ë£Œí•˜ëŠ” ì‹œê·¸ë„ í•¸ë“¤ëŸ¬

    Args:
        shutdown_event: multiprocessing.Event (í”„ë¡œì„¸ìŠ¤ê°„ ê³µìœ )
        cleanup_func: ì •ë¦¬ í•¨ìˆ˜ (ì„ íƒ)

    Returns:
        signal handler function
    """
    def signal_handler(sig, frame):
        print(f"\nâš ï¸ ì‹œê·¸ë„ {sig} ìˆ˜ì‹ . ì •ìƒ ì¢…ë£Œ ì‹œì‘...")

        # ì¢…ë£Œ í”Œë˜ê·¸ ì„¤ì • (ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ í™•ì¸ ê°€ëŠ¥)
        shutdown_event.set()

        # ì •ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ (ì„ íƒ)
        if cleanup_func:
            try:
                cleanup_func()
            except Exception as e:
                print(f"ì •ë¦¬ ì¤‘ ì—ëŸ¬: {e}")

        print("âœ… ì •ìƒ ì¢…ë£Œ ì™„ë£Œ")
        # sys.exit() í˜¸ì¶œí•˜ì§€ ì•ŠìŒ!

    return signal_handler


def setup_signal_handlers(shutdown_event: mp.Event, cleanup_func=None):
    """
    ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡

    Args:
        shutdown_event: ì¢…ë£Œ ì´ë²¤íŠ¸
        cleanup_func: ì •ë¦¬ í•¨ìˆ˜ (ì„ íƒ)

    Returns:
        signal handler
    """
    handler = create_signal_handler(shutdown_event, cleanup_func)

    # SIGINT (Ctrl+C)
    signal.signal(signal.SIGINT, handler)

    # SIGTERM (kill)
    signal.signal(signal.SIGTERM, handler)

    return handler
```

**ê¸°ìˆ  ìŠ¤í™**:
- `multiprocessing.Event`: í”„ë¡œì„¸ìŠ¤ê°„ ê³µìœ  ê°€ëŠ¥í•œ í”Œë˜ê·¸
- `shutdown_event.set()`: ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ `is_set()` ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥
- `sys.exit()` ì œê±°: ì˜ˆì™¸ ë°œìƒ ë°©ì§€

##### 4.2 ë©”ì¸ ë£¨í”„ ì¢…ë£Œ ë¡œì§

**ëŒ€ìƒ íŒŒì¼**: `test/main_multiprocessing.py`

```python
import multiprocessing as mp
from src.utils import setup_signal_handlers

class SensrMultiprocessingApp:
    def __init__(self, config, test_duration=None):
        self.config = config
        self.test_duration = test_duration

        # ì¢…ë£Œ ì´ë²¤íŠ¸ (í”„ë¡œì„¸ìŠ¤ê°„ ê³µìœ )
        self.shutdown_event = mp.Event()

        # ì»´í¬ë„ŒíŠ¸
        self.client = None
        self.processor = None
        self.bag_recorder = None

        # í†µê³„
        self.stats = {
            'start_time': None,
            'messages_received': 0,
            'messages_processed': 0,
            'messages_written': 0
        }

        self.is_running = False

    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡ (cleanup í•¨ìˆ˜ ì—†ì´)
        setup_signal_handlers(self.shutdown_event)

        try:
            # ì´ˆê¸°í™”
            self._initialize()

            # ë©”ì¸ ë£¨í”„
            self.is_running = True
            self.stats['start_time'] = time.time()

            self.logger.info(f"â±ï¸ {self.test_duration}ì´ˆ ë™ì•ˆ í…ŒìŠ¤íŠ¸")
            self.logger.info("="*70)

            while not self.shutdown_event.is_set():
                # í…ŒìŠ¤íŠ¸ ì‹œê°„ ì²´í¬
                if self.test_duration:
                    elapsed = time.time() - self.stats['start_time']
                    if elapsed >= self.test_duration:
                        self.logger.info(f"â±ï¸ í…ŒìŠ¤íŠ¸ ì‹œê°„ {self.test_duration}ì´ˆ ì™„ë£Œ")
                        break

                # ê²°ê³¼ ìˆ˜ì§‘ (non-blocking)
                self._collect_results(timeout=0.1)

                # ì£¼ê¸°ì  í†µê³„ ë¡œê¹… (10ì´ˆë§ˆë‹¤)
                if int(time.time()) % 10 == 0:
                    self._log_interim_stats()

                time.sleep(0.01)  # CPU ë¶€í•˜ ê°ì†Œ

        except Exception as e:
            self.logger.error(f"ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {e}", exc_info=True)

        finally:
            # ì •ìƒ ì¢…ë£Œ (ìˆœì„œ ì¤‘ìš”!)
            self._shutdown_gracefully()

    def _shutdown_gracefully(self):
        """4ë‹¨ê³„ ì •ìƒ ì¢…ë£Œ í”„ë¡œì„¸ìŠ¤"""
        self.logger.info("\n" + "="*70)
        self.logger.info("ğŸ›‘ ì •ìƒ ì¢…ë£Œ ì‹œì‘...")
        self.logger.info("="*70)

        # 1ë‹¨ê³„: WebSocket ì—°ê²° ì¢…ë£Œ (ìƒˆ ë©”ì‹œì§€ ìˆ˜ì‹  ì¤‘ë‹¨)
        if self.client:
            self.logger.info("1/4: WebSocket ì—°ê²° ì¢…ë£Œ ì¤‘...")
            try:
                self.client.disconnect()
                time.sleep(0.5)  # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸°
                self.logger.info("  âœ… WebSocket ì—°ê²° ì¢…ë£Œ ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"  âŒ WebSocket ì¢…ë£Œ ì—ëŸ¬: {e}")

        # 2ë‹¨ê³„: ì²˜ë¦¬ ì›Œì»¤ ì¢…ë£Œ (í í”ŒëŸ¬ì‹œ)
        if self.processor:
            self.logger.info("2/4: ì²˜ë¦¬ ì›Œì»¤ ì¢…ë£Œ ì¤‘...")
            try:
                self.processor.stop()
                time.sleep(1.0)  # ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°
                self.logger.info("  âœ… ì²˜ë¦¬ ì›Œì»¤ ì¢…ë£Œ ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"  âŒ ì²˜ë¦¬ ì›Œì»¤ ì¢…ë£Œ ì—ëŸ¬: {e}")

        # 3ë‹¨ê³„: Bag ë ˆì½”ë” ì¢…ë£Œ (ë””ìŠ¤í¬ í”ŒëŸ¬ì‹œ)
        if self.bag_recorder:
            self.logger.info("3/4: Bag ë ˆì½”ë” ì¢…ë£Œ ì¤‘...")
            try:
                # ë§ˆì§€ë§‰ ê²°ê³¼ ìˆ˜ì§‘
                remaining = self._collect_results(timeout=2.0, drain=True)
                self.logger.info(f"  - ë§ˆì§€ë§‰ {remaining}ê°œ ë©”ì‹œì§€ ìˆ˜ì§‘")

                # Bag íŒŒì¼ ë‹«ê¸°
                self.bag_recorder.stop()
                time.sleep(0.5)
                self.logger.info("  âœ… Bag ë ˆì½”ë” ì¢…ë£Œ ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"  âŒ Bag ë ˆì½”ë” ì¢…ë£Œ ì—ëŸ¬: {e}")

        # 4ë‹¨ê³„: ìµœì¢… ë¦¬í¬íŠ¸
        self.logger.info("4/4: ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        try:
            self._print_final_report()
            self.logger.info("  âœ… ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"  âŒ ë¦¬í¬íŠ¸ ìƒì„± ì—ëŸ¬: {e}")

        self.logger.info("="*70)
        self.logger.info("âœ… ì •ìƒ ì¢…ë£Œ ì™„ë£Œ")
        self.logger.info("="*70)

        self.is_running = False

    def _collect_results(self, timeout=0.1, drain=False):
        """
        ê²°ê³¼ ìˆ˜ì§‘

        Args:
            timeout: ëŒ€ê¸° ì‹œê°„
            drain: Trueë©´ íê°€ ë¹Œ ë•Œê¹Œì§€ ìˆ˜ì§‘

        Returns:
            int: ìˆ˜ì§‘ëœ ë©”ì‹œì§€ ìˆ˜
        """
        collected = 0

        while True:
            try:
                # ë°°ì¹˜ë¡œ ê°€ì ¸ì˜¤ê¸°
                results = self.processor.get_results(timeout=timeout, max_results=10)

                if not results:
                    if not drain:
                        break
                    else:
                        # drain ëª¨ë“œ: íê°€ ë¹„ì—ˆìœ¼ë©´ ì¢…ë£Œ
                        if self.processor.output_queue.qsize() == 0:
                            break
                        continue

                for result in results:
                    if result:
                        self.bag_recorder.write_message(result)
                        self.stats['messages_written'] += 1
                        collected += 1

            except Exception as e:
                self.logger.error(f"ê²°ê³¼ ìˆ˜ì§‘ ì—ëŸ¬: {e}")
                break

        return collected
```

**ê¸°ìˆ  ìŠ¤í™**:
- **4ë‹¨ê³„ ì¢…ë£Œ**: WebSocket â†’ ì²˜ë¦¬ â†’ ì“°ê¸° â†’ ë¦¬í¬íŠ¸
- **í ë“œë ˆì´ë‹**: `drain=True`ë¡œ ë§ˆì§€ë§‰ ë°ì´í„° ìˆ˜ì§‘
- **íƒ€ì„ì•„ì›ƒ ì„¤ì •**: ê° ë‹¨ê³„ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„
- **ì˜ˆì™¸ ì²˜ë¦¬**: ê° ë‹¨ê³„ ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰

##### 4.3 ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ë¡œì§

**ëŒ€ìƒ íŒŒì¼**: `src/data_processor_multiprocessing.py` (ìœ„ì—ì„œ ì´ë¯¸ êµ¬í˜„ë¨)

ìœ„ì˜ Priority 2ì—ì„œ êµ¬í˜„í•œ ì½”ë“œì— ì´ë¯¸ í¬í•¨:
- `shutdown_event` ì‚¬ìš©
- ê° ì›Œì»¤ì—ì„œ `shutdown_event.is_set()` ì²´í¬
- `None` ì‹ í˜¸ë¡œ ì¢…ë£Œ ìš”ì²­
- íƒ€ì„ì•„ì›ƒ ê¸°ë°˜ ê°•ì œ ì¢…ë£Œ

#### ê²€ì¦ ê¸°ì¤€ (Acceptance Criteria)

| ë²ˆí˜¸ | ê¸°ì¤€ | ì¸¡ì • ë°©ë²• | ëª©í‘œ |
|------|------|----------|------|
| 1 | **ì˜ˆì™¸ ì—†ëŠ” ì¢…ë£Œ** | ë¡œê·¸ì—ì„œ "Exception ignored" ê²€ìƒ‰ | 0íšŒ |
| 2 | **ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥** | "ìµœì¢… í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸" ì„¹ì…˜ ì¡´ì¬ | âœ“ |
| 3 | **ì›Œì»¤ ì •ìƒ ì¢…ë£Œ** | "ì •ìƒ ì¢…ë£Œ" ë¡œê·¸ í™•ì¸ | ëª¨ë“  ì›Œì»¤ |
| 4 | **ë°ì´í„° ì†ì‹¤ <1%** | í ë‚´ ë©”ì‹œì§€ ì²˜ë¦¬ìœ¨ | >99% |
| 5 | **ì¢…ë£Œ ì‹œê°„ <5ì´ˆ** | Ctrl+C í›„ ì¢…ë£Œê¹Œì§€ ì‹œê°„ | <5ì´ˆ |

---

### Priority 5: ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„ 

#### ëª©í‘œ
- âœ… ë©”ëª¨ë¦¬ ì¦ê°€ìœ¨ 11 MB/s â†’ **2 MB/s** (5.5ë°° ê°œì„ )
- âœ… 60ì´ˆ í…ŒìŠ¤íŠ¸ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ **<500 MB**
- âœ… ê°ì²´ ì¬ì‚¬ìš©ë¥  **>80%**

#### êµ¬í˜„ ì‚¬ì–‘

##### 5.1 ê°ì²´ í’€ í™•ì¥ ë° í™œìš©

**ëŒ€ìƒ íŒŒì¼**: `src/data_processor.py`

**í˜„ì¬** (Lines 140-142):
```python
self.header_pool = []
self.max_pool_size = 20  # ë„ˆë¬´ ì‘ìŒ
```

**ìˆ˜ì •**:
```python
class DataProcessor:
    def __init__(self, config):
        # ê¸°ì¡´ ì½”ë“œ...

        # í™•ì¥ëœ ê°ì²´ í’€ ì„¤ì •
        self.pool_config = {
            'header_pool_size': config.get('memory.header_pool_size', 100),
            'pointcloud_msg_pool_size': config.get('memory.pointcloud_msg_pool_size', 50),
            'numpy_buffer_pool_size': config.get('memory.numpy_buffer_pool_size', 30),
            'enable_pooling': config.get('memory.enable_pooling', True)
        }

        # ê°ì²´ í’€ ì´ˆê¸°í™”
        self.header_pool = []
        self.pointcloud_msg_pool = []
        self.numpy_buffer_pool = []  # (size, buffer) íŠœí”Œ ë¦¬ìŠ¤íŠ¸

        # í†µê³„
        self.pool_stats = {
            'header_reuse': 0,
            'header_new': 0,
            'pointcloud_reuse': 0,
            'pointcloud_new': 0,
            'numpy_reuse': 0,
            'numpy_new': 0
        }

    def _get_header(self):
        """í—¤ë” ê°ì²´ ê°€ì ¸ì˜¤ê¸° (í’€ ìš°ì„ )"""
        if self.header_pool and self.pool_config['enable_pooling']:
            self.pool_stats['header_reuse'] += 1
            return self.header_pool.pop()
        else:
            self.pool_stats['header_new'] += 1
            from std_msgs.msg import Header
            return Header()

    def _recycle_header(self, header):
        """í—¤ë” ê°ì²´ ì¬í™œìš©"""
        if not self.pool_config['enable_pooling']:
            return

        if len(self.header_pool) < self.pool_config['header_pool_size']:
            # í•„ë“œ ì´ˆê¸°í™”
            header.frame_id = ""
            header.stamp.sec = 0
            header.stamp.nanosec = 0
            self.header_pool.append(header)

    def _get_pointcloud_msg(self):
        """PointCloud2 ë©”ì‹œì§€ ê°ì²´ ê°€ì ¸ì˜¤ê¸°"""
        if self.pointcloud_msg_pool and self.pool_config['enable_pooling']:
            self.pool_stats['pointcloud_reuse'] += 1
            msg = self.pointcloud_msg_pool.pop()
            # ë°ì´í„° ì´ˆê¸°í™”
            msg.data = b''
            return msg
        else:
            self.pool_stats['pointcloud_new'] += 1
            from sensor_msgs.msg import PointCloud2
            return PointCloud2()

    def _recycle_pointcloud_msg(self, msg):
        """PointCloud2 ë©”ì‹œì§€ ì¬í™œìš©"""
        if not self.pool_config['enable_pooling']:
            return

        if len(self.pointcloud_msg_pool) < self.pool_config['pointcloud_msg_pool_size']:
            self.pointcloud_msg_pool.append(msg)

    def _get_numpy_buffer(self, size):
        """
        NumPy ë°°ì—´ ë²„í¼ ê°€ì ¸ì˜¤ê¸°

        Args:
            size: í•„ìš”í•œ ë°°ì—´ í¬ê¸° (í¬ì¸íŠ¸ ê°œìˆ˜)

        Returns:
            numpy.ndarray: ì¬ì‚¬ìš© ë˜ëŠ” ìƒˆ ë²„í¼
        """
        if not self.pool_config['enable_pooling']:
            self.pool_stats['numpy_new'] += 1
            return np.empty((size, 4), dtype=np.float32)

        # í¬ê¸°ê°€ ë§ëŠ” ë²„í¼ ì°¾ê¸° (Â±10% í—ˆìš©)
        for i, (buffer_size, buffer) in enumerate(self.numpy_buffer_pool):
            if 0.9 * size <= buffer_size <= 1.1 * size:
                self.pool_stats['numpy_reuse'] += 1
                self.numpy_buffer_pool.pop(i)
                # í•„ìš”í•œ í¬ê¸°ë§Œ ìŠ¬ë¼ì´ìŠ¤í•˜ì—¬ ë°˜í™˜
                return buffer[:size]

        # ì í•©í•œ ë²„í¼ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        self.pool_stats['numpy_new'] += 1
        return np.empty((size, 4), dtype=np.float32)

    def _recycle_numpy_buffer(self, buffer):
        """NumPy ë°°ì—´ ë²„í¼ ì¬í™œìš©"""
        if not self.pool_config['enable_pooling']:
            return

        if len(self.numpy_buffer_pool) < self.pool_config['numpy_buffer_pool_size']:
            self.numpy_buffer_pool.append((len(buffer), buffer))

    def get_pool_stats(self):
        """í’€ í†µê³„ ì¡°íšŒ"""
        total_header = self.pool_stats['header_reuse'] + self.pool_stats['header_new']
        total_pc = self.pool_stats['pointcloud_reuse'] + self.pool_stats['pointcloud_new']
        total_numpy = self.pool_stats['numpy_reuse'] + self.pool_stats['numpy_new']

        return {
            'header_reuse_rate': self.pool_stats['header_reuse'] / max(total_header, 1),
            'pointcloud_reuse_rate': self.pool_stats['pointcloud_reuse'] / max(total_pc, 1),
            'numpy_reuse_rate': self.pool_stats['numpy_reuse'] / max(total_numpy, 1),
            'stats': self.pool_stats.copy()
        }
```

**ê¸°ì¡´ í•¨ìˆ˜ ìˆ˜ì •**:
```python
def _create_ros_header(self, timestamp):
    """í—¤ë” ìƒì„± (í’€ ì‚¬ìš©)"""
    header = self._get_header()  # âœ… í’€ì—ì„œ ê°€ì ¸ì˜¤ê¸°

    header.frame_id = self.config.get('ros.frame_id', 'sensr')
    header.stamp = self._to_ros_time(timestamp)

    # âš ï¸ ì£¼ì˜: ë°˜í™˜ëœ í—¤ë”ëŠ” ë©”ì‹œì§€ì— ë³µì‚¬ë˜ë¯€ë¡œ ì¦‰ì‹œ ì¬í™œìš© ê°€ëŠ¥
    # í•˜ì§€ë§Œ ì•ˆì „ì„ ìœ„í•´ ë©”ì‹œì§€ ì²˜ë¦¬ í›„ ì¬í™œìš©

    return header

def _create_pointcloud2_message(self, pointcloud_data, timestamp):
    """PointCloud2 ë©”ì‹œì§€ ìƒì„± (í’€ ì‚¬ìš©)"""
    msg = self._get_pointcloud_msg()  # âœ… í’€ì—ì„œ ê°€ì ¸ì˜¤ê¸°

    msg.header = self._create_ros_header(timestamp)

    # NumPy ë²„í¼ ì‚¬ìš©
    points = pointcloud_data['points']
    intensities = pointcloud_data['intensities']
    num_points = len(points)

    # ì¬ì‚¬ìš© ë²„í¼ ê°€ì ¸ì˜¤ê¸°
    buffer = self._get_numpy_buffer(num_points)

    # In-place ë³µì‚¬
    buffer[:, :3] = points
    buffer[:, 3] = intensities.flatten()

    # PointCloud2 ë©”ì‹œì§€ í•„ë“œ ì„¤ì •
    msg.height = 1
    msg.width = num_points
    msg.fields = self._get_pointcloud_fields()
    msg.is_bigendian = False
    msg.point_step = 16
    msg.row_step = msg.point_step * num_points
    msg.is_dense = True
    msg.data = buffer.tobytes()

    # ë²„í¼ ì¬í™œìš© (tobytes í›„ì—ëŠ” buffer ì¬ì‚¬ìš© ê°€ëŠ¥)
    self._recycle_numpy_buffer(buffer)

    return msg

def _decode_pointcloud_protobuf(self, raw_data: bytes):
    """
    Protobuf ë””ì½”ë”© (ë©”ëª¨ë¦¬ ìµœì í™”)
    """
    # Protobuf íŒŒì‹±
    point_result = point_cloud_pb2.PointResult()
    point_result.ParseFromString(raw_data)

    # âœ… ì‚¬ì „ í• ë‹¹ (reallocation ë°©ì§€)
    total_points = sum(len(pc.points) // 12 for pc in point_result.points)

    # í’€ì—ì„œ ë²„í¼ ê°€ì ¸ì˜¤ê¸°
    points_buffer = self._get_numpy_buffer(total_points)
    intensities_array = np.empty(total_points, dtype=np.float32)

    # âœ… In-place ë³µì‚¬ (ì¤‘ê°„ ë°°ì—´ ìƒì„± ì—†ìŒ)
    offset = 0
    for point_cloud in point_result.points:
        points_data = point_cloud.points
        intensities_data = point_cloud.intensities

        num_points = len(points_data) // 12

        # frombuffer (ë³µì‚¬ ì—†ìŒ, viewë§Œ ìƒì„±)
        points_view = np.frombuffer(points_data, np.float32).reshape(-1, 3)
        intensities_view = np.frombuffer(intensities_data, np.float32)

        # ì‚¬ì „ í• ë‹¹ëœ ë²„í¼ì— ë³µì‚¬
        points_buffer[offset:offset+num_points, :3] = points_view
        intensities_array[offset:offset+num_points] = intensities_view

        offset += num_points

    # âœ… Protobuf ê°ì²´ ì¦‰ì‹œ ì‚­ì œ
    del point_result

    # ë²„í¼ëŠ” ì¬í™œìš©í•˜ì§€ ì•ŠìŒ (ë°˜í™˜ê°’ìœ¼ë¡œ ì‚¬ìš©ë¨)
    return points_buffer[:, :3].copy(), intensities_array
```

**ì„¤ì • ì¶”ê°€** (`config/config.yaml`):
```yaml
memory:
  # ê°ì²´ í’€
  header_pool_size: 100             # 20 â†’ 100
  pointcloud_msg_pool_size: 50      # ì‹ ê·œ
  numpy_buffer_pool_size: 30        # ì‹ ê·œ
  enable_pooling: true              # í’€ë§ í™œì„±í™”
```

##### 5.2 ëª…ì‹œì  ë©”ëª¨ë¦¬ í•´ì œ

**ëŒ€ìƒ íŒŒì¼**: `test/main_multiprocessing.py`

```python
def _collect_results(self, timeout=0.1, drain=False):
    """ê²°ê³¼ ìˆ˜ì§‘ (ë©”ëª¨ë¦¬ ê´€ë¦¬ ì¶”ê°€)"""
    collected = 0

    while True:
        try:
            results = self.processor.get_results(timeout=timeout, max_results=10)

            if not results:
                break

            for result in results:
                if result:
                    self.bag_recorder.write_message(result)
                    self.stats['messages_written'] += 1
                    collected += 1

                    # âœ… ëª…ì‹œì  ë©”ëª¨ë¦¬ í•´ì œ
                    # resultì˜ NumPy ë°°ì—´ ì‚­ì œ
                    if 'message' in result:
                        del result['message']
                    del result

            # âœ… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì‚­ì œ
            del results

            if not drain:
                break

        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ìˆ˜ì§‘ ì—ëŸ¬: {e}")
            break

    # âœ… ì£¼ê¸°ì  GC (100ê°œë§ˆë‹¤)
    if collected > 0 and collected % 100 == 0:
        import gc
        gc.collect(generation=0)  # Young generationë§Œ

    return collected
```

##### 5.3 ì ê·¹ì  GC ì •ì±…

**ëŒ€ìƒ íŒŒì¼**: `test/src/bag_recorder_optimized.py`

```python
import gc
import psutil

class BagRecorderOptimized:
    def __init__(self, config):
        # ê¸°ì¡´ ì½”ë“œ...

        # GC ì„¤ì •
        self.gc_config = {
            'gc_interval': config.get('memory.gc_interval', 10),  # 30 â†’ 10ì´ˆ
            'enable_aggressive_gc': config.get('memory.aggressive_gc', True),
            'max_memory_mb': config.get('memory.max_memory_mb', 1000)
        }

        # GC threshold ì„¤ì •
        if self.gc_config['enable_aggressive_gc']:
            # ê¸°ë³¸ê°’: (700, 10, 10)
            # ë” ìì£¼ ìˆ˜ì§‘í•˜ë„ë¡ threshold ê°ì†Œ
            gc.set_threshold(700, 10, 10)

    def _start_memory_management(self):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘"""
        self.memory_thread = threading.Thread(
            target=self._memory_management_worker,
            daemon=True,
            name="MemoryManager"
        )
        self.memory_thread.start()
        self.logger.info("ğŸ”§ ë©”ëª¨ë¦¬ ê´€ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘")

    def _memory_management_worker(self):
        """ì ê·¹ì  ë©”ëª¨ë¦¬ ê´€ë¦¬"""
        process = psutil.Process()

        while self.is_recording:
            time.sleep(self.gc_config['gc_interval'])

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
            mem_info = process.memory_info()
            mem_mb = mem_info.rss / 1024 / 1024

            self.logger.debug(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_mb:.1f} MB")

            # ì ê·¹ì  GC
            if self.gc_config['enable_aggressive_gc']:
                collected = gc.collect()

                if collected > 0:
                    new_mem = process.memory_info().rss / 1024 / 1024
                    freed = mem_mb - new_mem
                    self.logger.debug(
                        f"ğŸ—‘ï¸ GC: {collected}ê°œ ê°ì²´ ìˆ˜ì§‘, {freed:.1f} MB í•´ì œ"
                    )

            # ë©”ëª¨ë¦¬ ê²½ê³ 
            if mem_mb > self.gc_config['max_memory_mb']:
                self.logger.warning(
                    f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì„ê³„ê°’ ì´ˆê³¼: {mem_mb:.1f} MB > "
                    f"{self.gc_config['max_memory_mb']} MB"
                )
```

**ì„¤ì • ì¶”ê°€** (`config/config.yaml`):
```yaml
memory:
  # GC ì„¤ì •
  gc_interval: 10                   # GC ì£¼ê¸° (ì´ˆ, 30 â†’ 10)
  aggressive_gc: true               # ì ê·¹ì  GC
  max_memory_mb: 1000               # ê²½ê³  ì„ê³„ê°’ (MB)
```

#### ê²€ì¦ ê¸°ì¤€ (Acceptance Criteria)

| ë²ˆí˜¸ | ê¸°ì¤€ | ì¸¡ì • ë°©ë²• | ëª©í‘œ |
|------|------|----------|------|
| 1 | **ë©”ëª¨ë¦¬ ì¦ê°€ìœ¨ <2 MB/s** | (ì¢…ë£Œ - ì‹œì‘) / ì‹œê°„ | <2 MB/s |
| 2 | **ìµœëŒ€ ë©”ëª¨ë¦¬ <500 MB** | í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ì‹œì  ë©”ëª¨ë¦¬ | <500 MB |
| 3 | **ê°ì²´ ì¬ì‚¬ìš©ë¥  >80%** | reuse / (reuse + new) | >0.8 |
| 4 | **GC íš¨ìœ¨ì„±** | GC ë‹¹ í‰ê·  í•´ì œëŸ‰ | >10 MB |
| 5 | **ë©”ëª¨ë¦¬ ì•ˆì •ì„±** | Plateau í˜•ì„± í™•ì¸ | âœ“ |

---

## ğŸ“ ì „ì²´ ì„¤ì • íŒŒì¼ ìŠ¤í™

**íŒŒì¼**: `config/config.yaml`

```yaml
# ============================================================
# SENSR Multiprocessing Configuration
# Version: 2.0
# ============================================================

sensr:
  host: "122.202.187.5"
  ports:
    output_data: 5050
    point_cloud: 5051
  reconnect_interval: 5
  connection_timeout: 10

# ============================================================
# í ê´€ë¦¬ ë° ë°±í”„ë ˆì…”
# ============================================================
queue:
  # í í¬ê¸°
  max_items: 500                    # pointcloud ë²„í¼ í¬ê¸°
  output_max: 200                   # output ë²„í¼ í¬ê¸°

  # ë°±í”„ë ˆì…” ì„¤ì •
  high_watermark_pct: 0.8           # 80% ë„ë‹¬ ì‹œ ë°±í”„ë ˆì…” í™œì„±í™”
  drop_policy: "pointcloud_only"    # pointcloud_only | output_only | oldest

  # ë°°ì¹˜ ì „ë‹¬
  batch_size: 10                    # í•œ ë²ˆì— ì „ë‹¬í•  ë©”ì‹œì§€ ìˆ˜
  pump_interval_ms: 50              # íŒí”„ ë™ì‘ ì£¼ê¸° (ë°€ë¦¬ì´ˆ)

# ============================================================
# ë©€í‹°í”„ë¡œì„¸ì‹±
# ============================================================
multiprocessing:
  # ì›Œì»¤ ì„¤ì •
  num_workers: 4                    # Phase 1 ì›Œì»¤ ìˆ˜ (Protobuf â†’ NumPy)

  # í í¬ê¸°
  input_queue_size: 500             # Raw protobuf í (100 â†’ 500)
  numpy_queue_size: 200             # NumPy array í (ì‹ ê·œ)
  output_queue_size: 200            # ROS message í (1000 â†’ 200)

  # ì¢…ë£Œ ì„¤ì •
  shutdown_timeout_per_worker: 5    # ì›Œì»¤ë‹¹ ì¢…ë£Œ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
  force_kill_timeout: 10            # ì „ì²´ ê°•ì œ ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
  drain_queue_on_shutdown: true     # ì¢…ë£Œ ì‹œ í ë¹„ìš°ê¸°

# ============================================================
# ë ˆì½”ë”©
# ============================================================
recording:
  duration: 60                      # Bag íŒŒì¼ rotation ì£¼ê¸° (ì´ˆ)
  output_directory: "/mnt/f/radar"
  pointcloud_interval: 1.0          # í¬ì¸íŠ¸í´ë¼ìš°ë“œ ìƒ˜í”Œë§ ê°„ê²© (ì´ˆ)
  output_data_interval: 1.0         # Output ë°ì´í„° ê°„ê²© (ì´ˆ)
  pointcloud_only: false
  skip_empty_data: true
  track_log_enabled: true

# ============================================================
# Bag Writer
# ============================================================
bag_writer:
  queue_size: 200                   # Writer í í¬ê¸° (50 â†’ 200)
  enable_batching: true             # ë°°ì¹˜ ì“°ê¸° í™œì„±í™”
  batch_size: 20                    # ë°°ì¹˜ í¬ê¸°
  flush_interval_ms: 100            # ìµœëŒ€ í”ŒëŸ¬ì‹œ ì§€ì—° (ë°€ë¦¬ì´ˆ)

  # SQLite3 ìµœì í™”
  storage_optimization:
    journal_mode: "WAL"             # Write-Ahead Logging
    synchronous: "NORMAL"           # FULL | NORMAL | OFF
    cache_size: 10000               # 10MB ìºì‹œ
    page_size: 4096
    temp_store: "MEMORY"
    locking_mode: "EXCLUSIVE"

# ============================================================
# ë©”ëª¨ë¦¬ ê´€ë¦¬
# ============================================================
memory:
  # GC ì„¤ì •
  gc_interval: 10                   # GC ì£¼ê¸° (ì´ˆ, 30 â†’ 10)
  aggressive_gc: true               # ì ê·¹ì  GC
  max_memory_mb: 1000               # ê²½ê³  ì„ê³„ê°’ (MB)

  # ê°ì²´ í’€
  header_pool_size: 100             # 20 â†’ 100
  pointcloud_msg_pool_size: 50      # ì‹ ê·œ
  numpy_buffer_pool_size: 30        # ì‹ ê·œ
  enable_pooling: true              # í’€ë§ í™œì„±í™”

# ============================================================
# ëª¨ë‹ˆí„°ë§
# ============================================================
monitoring:
  queue_stats_interval: 5           # í í†µê³„ ë¡œê¹… ì£¼ê¸° (ì´ˆ)
  perf_metrics_interval: 10         # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹… (ì´ˆ)
  enable_detailed_stats: false      # ìƒì„¸ í†µê³„ (ì„±ëŠ¥ ì˜í–¥)
  memory_monitoring: true           # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

# ============================================================
# ë¡œê¹…
# ============================================================
logging:
  level: "INFO"                     # DEBUG | INFO | WARNING | ERROR
  file: "./logs/sensr_recorder.log"
  console_level: "INFO"
  file_level: "DEBUG"
  max_bytes: 10485760               # 10MB
  backup_count: 5

# ============================================================
# ROS2
# ============================================================
ros:
  frame_id: "sensr"
  topics:
    pointcloud: "/sensr/pointcloud"
    output: "/sensr/output"
    objects: "/sensr/objects"
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê³„íš

### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```bash
# í ê´€ë¦¬ í…ŒìŠ¤íŠ¸
pytest test/unit/test_queue_management.py -v

# ë©€í‹°í”„ë¡œì„¸ì‹± í…ŒìŠ¤íŠ¸
pytest test/unit/test_multiprocessing.py -v

# ë©”ëª¨ë¦¬ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
pytest test/unit/test_memory_management.py -v
```

### 2. í†µí•© í…ŒìŠ¤íŠ¸

#### 60ì´ˆ Soak í…ŒìŠ¤íŠ¸
```bash
./test/run_multiprocessing_wsl.sh

ê²€ì¦ í•­ëª©:
âœ… 60ì´ˆ ì™„ì£¼ (ì¤‘ë‹¨ ì—†ìŒ)
âœ… ì²˜ë¦¬ìœ¨ â‰¥8 msg/s
âœ… ë©”ì‹œì§€ ë“œë¡­ <5%
âœ… ë©”ëª¨ë¦¬ <500 MB
âœ… ì •ìƒ ì¢…ë£Œ
```

### 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

| í•­ëª© | Before | After | ê°œì„ ìœ¨ |
|------|--------|-------|--------|
| ì²˜ë¦¬ìœ¨ (msg/s) | 1.4 | 8.0+ | **5.7x** |
| í‰ê·  ì²˜ë¦¬ ì‹œê°„ (ms) | 329 | 125 | **2.6x** |
| ì“°ê¸° ì†ë„ (msg/s) | 2.3 | 10.0+ | **4.3x** |
| ë©”ëª¨ë¦¬ ì¦ê°€ìœ¨ (MB/s) | 11.0 | 2.0 | **5.5x** |
| ë©”ì‹œì§€ ë“œë¡­ë¥  (%) | 87.5 | <5 | **-94.6%p** |
| 60ì´ˆ í…ŒìŠ¤íŠ¸ | âœ— | âœ“ | - |
| ì •ìƒ ì¢…ë£Œ | âœ— | âœ“ | - |

---

## ğŸ“… êµ¬í˜„ ì¼ì •

### Phase 1: í ê´€ë¦¬ (2-3ì¼)
- Day 1: ë‹¤ì¸µ í ì•„í‚¤í…ì²˜ êµ¬í˜„
- Day 2: ë°±í”„ë ˆì…” ë° íŒí”„ êµ¬í˜„
- Day 3: ì„¤ì • íŒŒì¼ í™•ì¥, ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

### Phase 2: ì²˜ë¦¬ ìµœì í™” (3-4ì¼)
- Day 4: íŒŒì´í”„ë¼ì¸ ë¶„ë¦¬ (3ë‹¨ê³„)
- Day 5: ì„±ëŠ¥ ê³„ì¸¡ ì¶”ê°€
- Day 6-7: í†µí•© í…ŒìŠ¤íŠ¸ ë° íŠœë‹

### Phase 3: ë””ìŠ¤í¬ ì“°ê¸° (2ì¼)
- Day 8: ë°°ì¹˜ ì“°ê¸° í™œì„±í™”
- Day 9: SQLite3 ìµœì í™”, í…ŒìŠ¤íŠ¸

### Phase 4: ì •ìƒ ì¢…ë£Œ (2ì¼)
- Day 10: ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë¦¬íŒ©í† ë§
- Day 11: ì¢…ë£Œ ë¡œì§ êµ¬í˜„, í…ŒìŠ¤íŠ¸

### Phase 5: ë©”ëª¨ë¦¬ ê´€ë¦¬ (2-3ì¼)
- Day 12: ê°ì²´ í’€ í™•ì¥
- Day 13: ëª…ì‹œì  ë©”ëª¨ë¦¬ í•´ì œ
- Day 14: GC ìµœì í™”

### Phase 6: í†µí•© ë° ê²€ì¦ (2ì¼)
- Day 15: ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸
- Day 16: ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬, ë¬¸ì„œí™”

**ì´ ì˜ˆìƒ ê¸°ê°„**: 15-17ì¼

---

## ğŸš¨ ìœ„í—˜ ìš”ì†Œ ë° ì™„í™” ì „ëµ

### Risk 1: GIL ê²½í•©
**ìœ„í—˜**: NumPy ì—°ì‚° ì¤‘ GILë¡œ ì¸í•œ ë³‘ë ¬í™” ì œí•œ
**ì™„í™”**: íŒŒì´í”„ë¼ì¸ ë¶„ë¦¬, Cython ê°€ì† (ì„ íƒ)

### Risk 2: ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë²„í—¤ë“œ
**ìœ„í—˜**: í”„ë¡œì„¸ìŠ¤ê°„ í ì „ë‹¬ ë¹„ìš©
**ì™„í™”**: ë°°ì¹˜ ì „ë‹¬, ê³µìœ  ë©”ëª¨ë¦¬ ê²€í†  (ì„ íƒ)

### Risk 3: ë””ìŠ¤í¬ I/O ë³‘ëª©
**ìœ„í—˜**: SSD ì†ë„ í•œê³„
**ì™„í™”**: ë°°ì¹˜ ì“°ê¸°, WAL ëª¨ë“œ

### Risk 4: ë©”ëª¨ë¦¬ ë‹¨í¸í™”
**ìœ„í—˜**: ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ ë‹¨í¸í™”
**ì™„í™”**: ê°ì²´ í’€, ì ê·¹ì  GC

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

### êµ¬í˜„ ì „
- [ ] í˜„ì¬ ì½”ë“œ ë°±ì—…
- [ ] Git ë¸Œëœì¹˜ ìƒì„±
- [ ] í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„

### ê° Priority ì™„ë£Œ í›„
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ì½”ë“œ ë¦¬ë·°
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸
- [ ] Git ì»¤ë°‹

### ìµœì¢… ê²€ì¦
- [ ] 60ì´ˆ soak í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ëª©í‘œ ë‹¬ì„±
- [ ] ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ í™•ì¸
- [ ] ì‚¬ìš©ì ë¬¸ì„œ ì‘ì„±

---

**ë¬¸ì„œ ë**

ì‘ì„±ì: Claude Code Assistant
ìµœì¢… ìˆ˜ì •: 2025-11-12
